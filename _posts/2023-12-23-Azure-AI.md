---
layout: post
title:  Azure AI
date:   2023-12-23 1:28:47 +05:30
tags:
  - AI
  - azure
description: Azure AI
---

### Module 1 - [Fundamental AI Concepts](https://learn.microsoft.com/en-in/training/modules/get-started-ai-fundamentals/?WT.mc_id=cloudskillschallenge_8E1F62A7-99E3-48E4-9EC9-1FFFB99EE9AF)

AI is a software that imitates human behaviours and capabilities.(MNCDKG)

| AI Type                               | Description                                           | Microsoft Azure Services                                      |
|---------------------------------------|-------------------------------------------------------|------------------------------------------------------|
| Machine Learning             | Captures relationships between data and draws conclusions          | Azure Machine Learning Studio |
| Computer Vision        | Deals with visual processing - image classification,object detection, | Azure AI Vision  |
|                           | image analysis, face detection & recognition, OCR (detect & read text in images)                                   |                                                                 |
| Natural Language Processing          | Analyzes written and spoken language and commands                    | Azure AI Language, Azure AI Speech           |
| Document Intelligence         | Manages, processes, and uses high volumes of varied data                                  | Azure AI Document Intelligence           |
| Knowledge Mining    | Extracts information from large volumes of data to create a searchable knowledge store | Azure AI Cognitive Search                                |
| Generative AI     | Creates original content in a variety of formats | Azure OpenAI service                                 |

<!-- Note: **Data Mining** focuses on searching and indexing of data 

**Challenges and Risks in AI:** Bias, Error harm, Data exposure, Inclusivity risk, Trust challenge, Liability challenge  (FRSPSITA) -->

**6 principles**: Fairness, Reliability and Safety, Privacy and Security, Inclusivness, Transparency, Accountability.

* * *

### Module 2 - [Use Automated Machine Learning in Azure Machine Learning](https://learn.microsoft.com/en-in/training/modules/use-automated-machine-learning/?WT.mc_id=cloudskillschallenge_8E1F62A7-99E3-48E4-9EC9-1FFFB99EE9AF)

Machine Learning is an AI tool that uses mathematics and statistics to create a model that can predict unknown values.
F(x)=y where x -> features and y -> labels we are trying to predict.

<!-- Process of defining the function is called **training** & the process of predicting new values is called **inferencing** -->

1) **Supervised Machine Learning**: 
Algo trained on **labelled dataset (labels & features known)**
- **Regression** - used to predict a numerical value - **does not rely on randomly generated data for training**

<!--   - **Linear regression:** uses single feature
  - **Multiple linear regression:** relationship between two or more features and a single label - **Assumptions include** that **features are independent of each other** orelse models may make **misleading predictions** -->

- **Classification** - used to predict a category or class 

<!--   - **Binary Classification** - predicts one of two mutually exclusive outcomes - predicts a binary true/false or positive/negative prediction for a single possible class - e.g. diabetic or not diabetic - algo such has **logistic regression** derives **sigmoid (S-shaped) function**
  - **Multiclass classification** - predicts multiple possible classes - may be more than one valid label for single obs - e.g. movie can be both scifi and comedy - 2 types of algo can be used - **Decision Forest**
    - **One-vs-Rest (OvR) algorithms**
    - **Multinomial algorithms** - creates single function that **returns multi-valued output** - output is a **vector** that contains **probability distribution & probability score** 

Note: **Logistic regression:** type of classification model - return Boolean value or categorial decision -->

2) **Unsupervised Machine Learning:** 
Algo trained without any predefined labels **(features and labels not known)**
- **Clustering** - grouping similar items together based on their features **without relying on training and validating label predictions**

<!-- 
3) **Deep Learning:** creation of artificial neural network - models produced by it called **deep neural networks (DNNs)** - https://learn.microsoft.com/en-us/training/modules/fundamentals-machine-learning/8-deep-learning

**Other Terms:**
- **Endpoint:** the HTTP address (URL) at which service is deployed/accessed.
- **Key:** a secret value used by client applications to authenticate/prove 

Note: When you write code, keys and endpoints must be included in authentication header, which sends authorization key to service to confirm that the app can use resource.  -->

<!-- Refer to this **Lab 1** link - [Azure Automated Machine Learning](https://microsoftlearning.github.io/AI-900-AIFundamentals/instructions/02-module-02.html)

	
**1) Select dataset**, **2) Use algorithm to train the model**

**3) Evaluate performance:**

**Cross Validation:** compare predicted value and actual value. **Residuals:** difference between the predicted and actual value (error). **R2 square:** Metric range from 0 to 1 - **for the best possible R2 score, set the primary metric to R2 score** - higher value, better model. **RMSE (Root mean squared error):** squaring errors of all test cases, finding mean of these squares, and then taking square root - smaller value, more accurate model. **NRMSE (Normalized RMSE):** standardizes the RMSE metric so it can be used for comparison between models which have variables on different scales 
	
**4) Deploy a predictive service:** Can deploy service as **ACI (Azure Container Instances)** or **AKS (Azure Kubernates Services).** 4 kinds of Compute Resources: Compute Instances, Compute Clusters, Kubernetes Clusters and Attached Compute 

Note: **After preparing dataset and before training** the machine learning model - **split data** into training and validation datasets  -->

* * *

### Module 3 - [Create a Regression Model with Azure Machine Learning Designer](https://learn.microsoft.com/en-in/training/modules/create-regression-model-azure-machine-learning-designer/?WT.mc_id=cloudskillschallenge_8E1F62A7-99E3-48E4-9EC9-1FFFB99EE9AF)

#### Azure Machine Learning Studio: 
To begin use of it, you need to **associate resource created in Azure portal to Azure Machine Learning studio**.

**Azure Automated ML:** automatically trains ML model by providing dataset and picking label i.e. **automatically pick algo** - ((DICY))allows to include **custom python script** - uses **solns without need of programming**.

**Azure ML Designer:** provides **drag-and-drop interface/ canvas** to train, test and deploy ML models - enables to **save progress** as a **pipeline draft** - allows **custom python & R fns ~~and not JS functions~~**.

**Azure ML Jobs:** It **executes a task** against a specified computer target and keeps a **track/run record for the job**. Each time you **run** a pipeline, the configuration of the pipeline and its **results are stored** in your workspace as a pipeline job.
	
**Pipelines:** Each **designer project**, known as pipeline, has a left panel for navigation and a canvas on your right hand side. It starts with a dataset from which you train a model. In pipeline project, you can access **data assets** and **components** from the left panels Asset Library tab. 

Refer to this **Lab 2** link - [Explore regression with Azure Machine Learning Designer](https://microsoftlearning.github.io/AI-900-AIFundamentals/instructions/02a-create-regression-model.html)

#### UNDERSTAND STEPS FOR REGRESSION:

**1) Prepare Data:** Either create **own dataset** in Azure ML Studio or **choose** from **azure storage, local files, web files, or from SQL databases**.

<!-- 
| **Module**                        | Function                                            |
| ----------------------------- | --------------------------------------------------- |
| Select columns in dataset     | To choose specific columns/features from dataset   |
| Clean missing data module     | To handle missing values within the dataset        |
| Normalize data module         | Changing values to be on a similar scale            |
| Split data module             | Will **randomly** split **into rows** for training and validation datasets to compare labels that model predicts to actual known labels  |
| Join data module              | Will join datasets together                         |

- When training model, **randomly split rows** into seperate subsets - to **test model** by **using data** that was **not used to train** the model. -->

**2) Train the Model:**

<!-- ![trainmodel](https://cdn.discordapp.com/attachments/1173139022688829511/1182362931623628931/train-score.png?ex=65846c4a&is=6571f74a&hm=130c8b5c1abc03ff3bb7c923d71406d43f0eaff92aef8352ad5011b9b07c0200&) -->

**3) Evaluate Performance:** Metrics are Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), Relative Squared Error (RSE), Relative Absolute Error (RAE) and Coefficient of Determination (R^2).
	
<!-- | Metric                               | Description                                           | Interpretation                                      |
|---------------------------------------|-------------------------------------------------------|------------------------------------------------------|
| Mean Absolute Error **(MAE)**             | Avg diff between predicted and actual values          | Lower value is better; units same as values and labels |
| Root Mean Squared Error (**RMSE)**        | Larger difference indicates greater variance         | Lower value is better; units same as values and labels |
| Relative Squared Error **(RSE)**          | Range 0 to 1; Closer to 0 is better                    | Values and labels can have different units           |
| Relative Absolute Error **(RAE)**         | Closer to 0 is better                                  | Values and labels can have different units           |
| Coefficient of Determination **(R^2)**    | Summarizes difference between predicted and true values | Closer to 1 is better                                 | -->

**4) Deploy a predictive service:** 
	After creating the interference pipeline, you can **deploy it as an endpoint**. Deployment state can be viewed on the Details page and will indicated **healthy when deployment is complete**. On Test tab, you can test your deployed service with a sample data in **JSON format** (used to **indicate recording pattern of data**).

<!-- - Note: **Azure's indexer** is a tool that **exports incoming doc** into JSON and pushes JSON to an index for blob storage  -->

* * *

### Module 4 - [Create a classification model with Azure Machine Learning Designer]()

Refer to **Lab 3** link [Explore classification with Azure Machine Learning Designer](https://microsoftlearning.github.io/AI-900-AIFundamentals/instructions/02b-create-classification-model.html)

#### UNDERSTAND STEPS FOR CLASSIFICATION:
**1) Prepare Data, 2) Train Model** 
	
**3) Evaluate Performance:**

**Confusion Matrix:**
It is a tool to **assess the quality of a classification models predictions**.

![matrix](https://cdn.discordapp.com/attachments/1173139022688829511/1190696091973320854/Screenshot_2023-12-30_at_10.10.12_PM.png?ex=65a2bd26&is=65904826&hm=7a80986f4d50861cfdc8647074ffd8daa7669c656e486e98af968550cd431dd5&)

<!-- different pic (https://cdn.discordapp.com/attachments/1173139022688829511/1180000991089807430/Screenshot_2023-12-01_at_9.50.50_AM.png?ex=657bd48f&is=65695f8f&hm=ac80b2608022088e79c1fc32f43c96c6f0e7a4595f94eea27373c456c5eaa015&) -->

<!-- **True Positive:** Model correctly predicts the positive class, **True Negative:** Model correctly predicts the negative class  -->
	
**Metrics that can be derived from confusion matrix:** Accuracy, Precision, Recall, F1 Score.

<!-- - **Accuracy:** (TP+FP)/(TP+TN+FP+FN) -> no. of correct predictions
- **Precision:** TP/(TP+FP) -> proportion of predicted positive cases where true label is actually positive
- **Recall/TPR:** Positive cases correctly identified (**relevant instances**) -> TP/(TP+FN)
- **F1 Score:** (2 x Precision x Recall)/(Precision + Recall)

**FPR** -> false + rate = FP/(FP+TN) -> no. of negative cases correctly identified -->

<!-- **5) Threshold & ROC v/s AUC:**

Designer has a **threshold slider** for reviewing how model performance would change depending on the set threshold. 

#### ROC (Receiver operation characteristic) curve and AUC(Area under curve) metric:

**- ROC Curve:** graphical representation **TPR v/s FPR** at different threshold values (ranging from 0 to 1).

**- AUC** is a **numerical measure** of the **ROC curve's performance** - area under RUC - closer to 1 better - **random guessing** is **0.5** (0.5-0.7 poor, 0.7-0.8 ok, 0.8-0.9 very good)

**6) Inference Pipelines:** In order to automate model into a service, need to create and deploy interference pipeline by first converting training pipeline into a **real-time interference pipeline**. This **removes training components** and **adds web service inputs and outputs** to handle requests. 

![deployment](https://cdn.discordapp.com/attachments/1173139022688829511/1180000992448749639/Screenshot_2023-12-01_at_9.51.37_AM.png?ex=657bd48f&is=65695f8f&hm=3a497508a08319aed1801f3fd9087392bacf28c4a594c3457e0188ba5c7840c8&)

**7) Deployment** (explained earlier) -->

* * *

### Module 5 - [Create a clustering model with Azure ML Designer](https://learn.microsoft.com/en-in/training/modules/create-clustering-model-azure-machine-learning-designer/?WT.mc_id=cloudskillschallenge_8E1F62A7-99E3-48E4-9EC9-1FFFB99EE9AF&ns-enrollment-type=Collection&ns-enrollment-id=67pkuw8qe4j4)

Refer to **Lab 4** link [Create a clustering model with Azure ML Designer](https://microsoftlearning.github.io/AI-900-AIFundamentals/instructions/02c-create-clustering-model.html)

#### UNDERSTAND STEPS FOR CLUSTERING:

**1) Prepare data**

**2) Train model:**
To train a clustering model, you need to apply a clustering algorithm to the data. 
**[K- Means Clustering Algorithm](https://www.youtube.com/watch?v=4b5d3muPQmA)**
groups items into numbers of clusters, or centroids i.e. 'K'. 
	
**K-Means Algorithm - How it works?**

- Initializing **K coordinates** as randomly selected points called **centroids**.
- **Plotting** and **assigning each point to its closest centroid**.
- **Moving the centroids to the middle of the points allocated** to it. **Reassigning the points to their closest centroid** after the move.
- **Repeating** steps 3 and 4 until the cluster allocations **stabilize**.

**3) Evaluate Performance:** 


| Metric                             | Description                                                                                                              |
|-------------------------------------|--------------------------------------------------------------------------------------------------------------------------|
| **Average Distance** to **Other Center**    | Distance of each point in the cluster to the centroids of all other clusters.                                            |
| Average Distance to **Cluster Center**  | Distance of each point in the cluster is to the centroid of the cluster.                                                  |
| Number of **Points**                    | The number of points assigned to the cluster.                                                                            |
| **Maximal Distance** to Cluster Center  | The maximum of the distances between each point and the centroid of that pointâ€™s cluster. If high, indicates dispersion/spread.   |

| **Silhouette** | Ratio of distance between points in same cluster and points in different clusters - closer to 1, better cluster seperation - range -1 to 1  |

<!-- ![evaluate](https://cdn.discordapp.com/attachments/1173139022688829511/1180003884878528634/Screenshot_2023-12-01_at_10.02.43_AM.png?ex=657bd741&is=65696241&hm=279dd18fabd80e184da0753dca6d2990b0cead688f4878eb11fa788acb1d3fe5&)

**4) Interference Pipeline:** For interference pipeline, make following changes:
![changes](https://cdn.discordapp.com/attachments/1173139022688829511/1180003886128447558/Screenshot_2023-12-01_at_10.03.10_AM.png?ex=657bd741&is=65696241&hm=7fa3d839f13653936bab53db5a95f1e2c0103b967454458d9c5acb36288b9501&) -->

**5) Deployment**: (explained earlier)

#### Summary (IMPORTANT):

**Regression Model:** 
Raw Data -> Select Columns in Dataset -> Clean Missing Data -> Normalize data -> Split data & **Linear Regression** -> Train Model -> Score Model

**Classification Model:** 
Raw data -> Select Columns in Dataset -> Normalize data -> Split data & **Two-Class Logistic Regression** -> Train Model -> Score Model -> Evaluate Model

**Clustering Model:**
Raw data -> Select Columns in Dataset -> Clean Missing data -> Normaize data -> Split data & **K-Means Clustering** -> **Train Clustering Model** -> **Assign Data to Clusters** **(used to generate cluster predictions)** -> Evaluate Model

* * *

### Module 6 - [Computer Vision](https://learn.microsoft.com/en-in/training/modules/analyze-images-computer-vision/?WT.mc_id=cloudskillschallenge_8E1F62A7-99E3-48E4-9EC9-1FFFB99EE9AF)

**Computer Vision** - manipulation and analysis of pixel values in images.

Azure Services for computer vision:
- **Azure Computer Vision Read API**: Describe, tag, (brand, object, face) detect, categorize img, landmark and celeb, generate thumbnails, and detect inappropriate content
- **Azure Custom Vision**: Analayze, classify images and detect objects (class label, probability and bounding box)
- **Azure AI Face**
- **Azure AI Video**
- **Azure AI Document Intelligence / Azure Forms Recognizer**
- **Azure Cognitive Services** (includes **all services** - uses only **one endpoint and key** - can be used for **both training and prediction**)

<!-- **Abilities of Computer Vision:** IMP
	1) **Describe Images:** Short phrases/ sentences describe the image - confidence number between 0 to 1 - sorted in descending order based on confidence 
	2) **Tagging:** suggests key terms/ tags for an image
	3) **Object Detection:** and **bounding box** (indicate location)
	4) **Brand Detection:**, confidence score and a bounding box
	5) **Facial Detection:** and not Facial Recognition - i.e. it simply determines if there is a face, the age and a bounding box
	6) **Categorize Images:** based on 86 pre-defined categories
	7) **Landmarks and Celebrities:** and a confidence score
	8) **OCR/ Reading text from picture**
	9) **Generate thumbnails**
	10) **Detect images** with adult content, violent content or gory scenes -->

[Refer to **6A** Analyze image in Azure AI Vision](https://microsoftlearning.github.io/mslearn-ai-fundamentals/Instructions/Labs/03-image-analysis.html)

**Azure AI Custom Vision:** 

Image recognition service to build, deploy and improve **your own image identifier model** - **you provide your own data to train model** - can specify **whether used for training, prediction or both**

[Refer to **6B** Classify images with Azure AI Custom Vision](https://learn.microsoft.com/en-in/training/modules/classify-images-custom-vision/?WT.mc_id=cloudskillschallenge_8E1F62A7-99E3-48E4-9EC9-1FFFB99EE9AF)

<!-- Create new project - enter req credentials - add images and add tags to those images - upload the training model and evaluate - select a random image and check that tag and probability for that image  -->

<!-- 1) **Model Training:** **Upload** images - train - **label/tag** them

2) **Model Evaluation:** Trained on basis of **3** evaluation **metrics**: 
- **Precision:** measures **accuracy of +ve predictions** e.g. model predicted 10 oranges of which 8 are correct -> precision=0.8 (80%)
- **Recall:** models ability to **identify relevant instances** e.g. 10 apple images and model detects 7 -> recall = 0.7 (70%)
- **Average Precision (AP):** An overall metric that accounts **both precision and recall**.

**Publishing Model:**
When publishing, **assign name** (**IterationX** where **X** is **no.** of times you have **trained** the model).
To use model, client needs these info 
- **Project ID**
- **Model Name**
- **Prediction (REST) endpoint**: HTTP address of the endpoint for prediction resource (not training resource)
- **Prediction key**: **authentication** key for prediction resource (not training resource)

[Refer to **6C** Detect Objects with Azure AI Custom Vision](https://learn.microsoft.com/en-in/training/modules/detect-objects-images-custom-vision/?WT.mc_id=cloudskillschallenge_8E1F62A7-99E3-48E4-9EC9-1FFFB99EE9AF&ns-enrollment-type=Collection&ns-enrollment-id=67pkuw8qe4j4)

**Object Detection:** **class label, probability and bounding box** -->

#### [Fundamentals of Facial Recognition](https://learn.microsoft.com/en-in/training/modules/detect-analyze-faces/?WT.mc_id=cloudskillschallenge_8E1F62A7-99E3-48E4-9EC9-1FFFB99EE9AF&ns-enrollment-type=Collection&ns-enrollment-id=67pkuw8qe4j4)

**To detect faces** in Vision Studio, first **make face resource in Azure AI Vision** and the **upload** and **analyze** photos.

**Azure Services:**
- **Azure AI Vision**: face detection & analysis (bounding box coordinates)
- **Azure AI Video Indexer**: detect and identify faces in video
- **Azure AI Face**: **detect, recognize, and analyze** faces - returns **set of coordinates for each face**, a **rect bounding box** 
  - **Face identification:** One-to-many face matching 
  - **Face verification:** One-to-one face matching 
- **Azure Cognitive Services**: The one service to rule them all!

<!-- **Features:**
- **identify accessories**, **blurred**, **exposure** (over exposed/under exposed), **glasses**, **head pose** (pitch, roll, yaw), **mask**, **noise**, **occlusion** (if objects are blocking face)
- Additional Capabilities (**submit in-take form and get approval**) - **compare faces** for similarity, **identify name** of individual 

**Noise** - refers to **visual noise** in image - **high ISO setting for darker environments**:

For more **accurate results**:
- **Faces are full-frontal** or near to that.
- **Shutter speed** applies to video more than images however, **faster** shutter speeds tend to create a **sharper image**, which is beneficial to facial detection
- Image format - **JPEG, PNG, GIF, BMP**
- **File size** 6MB or smaller
- **Face size range** - 36x36 pixels to 4096x4096 pixels -->

#### [Fundamentals of Optical Character Recognition](https://microsoftlearning.github.io/mslearn-ai-fundamentals/Instructions/Labs/05-ocr.html)


<!-- **Azure AI Vision service** - extract text from images - one of the **service is Read API** (**OCR engine** that **extracts text** from **images, PDFs and TIFF files** - Results from Read API are in following order:
- Page: **page size** and **orientation** for each page. 
- Lines: **lines of text** on page
- Words: **words** in line of text, **bounding box** and text -->

Azure Services:
- **Azure AI Vision** - to track utilization and costs for AI Vision resource separately - **for image analysis**
- **Azure AI Language** - for **text analytics**
- **Azure AI Cognitive Services** - include Azure AI Vision and many other services - **used when** want to **simplify administration and deployment**


#### [Fundamentals of Azure AI Document Intelligence](https://learn.microsoft.com/en-in/training/modules/analyze-receipts-form-recognizer/?WT.mc_id=cloudskillschallenge_8E1F62A7-99E3-48E4-9EC9-1FFFB99EE9AF&ns-enrollment-type=Collection&ns-enrollment-id=67pkuw8qe4j4)

**Azure AI Document Intelligence/ Azure Forms Recognizer service**: best way to **read text from images** of **reciepts, invoices and forms**, automates process of **extracting, understanding and saving data** in text

  - **Document Analysis:** ability to extract **text, layout, and key-value pairs** - **location of text** along with **bounding box coordinates**

<!-- **Features grouped by model type:**

- **Prebuilt model:** the **max file size** is **50 MB** - built to **process common document** such as invoices, receipts, forms, business cards, ID documents - **identify text and extract text**, **key-value pairs**, tables, and **structures from forms and documents**, **confidence level**
  - For **best result**:
    - **JPEG, PNG, BMP, PDF, TIFF** format
    - **File size** < 500 MB for paid (S0) tier and 4 MB for free (F0) tier
    - Between 50x50 pixels and 10000x10000 pixels
    - For PDF doc, not more than 17 inches x 17 inches
    - One receipt per document

- **Receipt model** - trained to **recognize data** on **several receipt types** e.g. thermal receipts, hotel, gas, credit card receipts etc.

- **Custom models** - can be trained to **identify specific fields not included in prebuilt models**

- **Document analysis** - returns **structured data representations**, incl regions of **interest and inter-relationships**

**To use receipt analyzer service** in Azure AI Document Intelligence, **first create** an **azure AI Document Intelligence Resource** -->

<!-- #### [Fundamentals of Knowledge Mining and Azure AI search](https://learn.microsoft.com/en-us/training/modules/intro-to-azure-search/)

**Azure AI Search**: extract data from **structures, semi-structures and non-structured** documents - it is a **PaaS solution**

**Features**:
- Provides **programmable search engine** built on **Apache Lucene** (open source software library) - 99.9% uptime
- **Accepts data from any source** provided in **JSON** format
- **Full text search and analysis** in **simple query** and **full Lucene query syntax**
- **AI powered search** - **image and text analysis** from raw content
- **Multi-lingual** - 56 languages to handle phonetic matching/ language specififc linguistics - also **used by Bing and Office**
- **Geo-enabled** - supports **geo-serach filtering** based on physical **location**
- **Configurable user experience** - **autocomplete, auto suggest, pagination, hit higlighting**

Azure AI Search - starts with data source - can be hierarchy of folders and files in Azure sStorage or text in database such as Azure SQL Database or Azure Cosmos DB - supports JSON format

Azure Indexer: connects to data source, serializes data, passes to search engine for indexing
  - also support AI enrichment - can attach ai skills to enrich data 

Using skillset to define enrichment pipeline:
adding/combining skills in a skillset - ai skills can be built in skills or custom skills

  - Built in skills: unstructured text is mapped as searchable and filterable fields in an index
    - NLP processing skills:
      - Key Phrase Extraction
      - Text Translation Skills
    - Image processing skills: image content is serachable using query
      - Image analysis skill
      - OCR

Enriched content can be sent to knowledge store - stores output from AI enrichment pipeline in tables and blobs in Azure Storage for independent analysis or downstream processing

Azure AI Search index - though of as container of serachable docs 
- Index Schema: index is collection of JSON docs - docs within index can be thought of as rows in a table - each doc is single unit of serachable data in index 
  - Schema: definition of structure of data in doc

- Index Attributes

Azure AI Search lets to create and load JSON doc into an index in two approaches:
- Push method: JSON data is pushed into search index via REST API/ or .NET SDK - no restrictions
- Pull method: Search index can pull data from popular Azure data sources


Knowledge store: store data generated from AI enrichment in a container - can contain one or more of three types of projection of extracted data:
- Table projections: to structure extracted data in relational schema for querying and visualization
- Object projections: JSON doc that represent each data entity
- File projections: used to store extracted images in JPG format

Supported data sources include:
- Cosmos DB (SQL API)
- Azure SQL (database, managed instance, and SQL Server on an Azure VM)
- Azure Storage (Blob storage, Table storage, ADLS Gen 2)

Once data in Azure data source, you can begin using Azure AI Search
Terms:
- Data Source: Persists connection information to source data, including credentials. A data source object is used exclusively with indexers.
- Index: Physical data structure used for full text search and other queries.
- Indexer: A configuration object specifying a data source, target index, an optional AI skillset, optional schedule, and optional configuration settings for error handling and base-64 encoding.
- Skillset: A complete set of instructions for manipulating, transforming, and shaping content, including analyzing and extracting information from image files. Except for very simple and limited structures, it includes a reference to an Azure AI services resource that provides enrichment.
- Knowledge store: Stores output from an AI enrichment pipeline in tables and blobs in Azure Storage for independent analysis or downstream processing. -->


* * *

### Module 7 - [Natural Language Processing](https://learn.microsoft.com/en-in/training/modules/build-faq-chatbot-qna-maker-azure-bot-service/?WT.mc_id=cloudskillschallenge_8E1F62A7-99E3-48E4-9EC9-1FFFB99EE9AF&ns-enrollment-type=Collection&ns-enrollment-id=67pkuw8qe4j4)

**Process to make bot:**
- First **make Language resource** - **use Language Studio's custom qs ans feature** - **qs ans** can be generated by **importing** an existing **FAQ doc/ web page** or **entered manually** with additional manual entries - **save it**. 
- **After created and deployed a knowledge base**, you can **deliver** it to users through a bot - create **custom bot** using **Microsoft Bot Framework SDK** ( writes code - integrates with knowledge base) 

#### [Fundamentals of Text Analysis with the Language Service](https://learn.microsoft.com/en-in/training/modules/analyze-text-with-text-analytics-service/?WT.mc_id=cloudskillschallenge_8E1F62A7-99E3-48E4-9EC9-1FFFB99EE9AF&ns-enrollment-type=Collection&ns-enrollment-id=67pkuw8qe4j4)

<!-- **Earlier techniques for Text Analytics:**
- **Tokenization:** First step is to analyze corpus and break it down into tokens 
  - Following concepts may be applied based on NLP problem:
    - **Text Normalization:** normalize text by removing punctuation and changing all words to lowercase - meaning may be lost - may not be able to differentiate between words 
    - **Stop word removal:** **first step in statistical analysis of terms** - stop words are those words that should be excluded from the analysis - e.g. "the", "a" or "it" make easier for people to read but exclusing them will make it better to identify imp words
    - **N-Grams:** **multi-term phrases** such as "I have" or "he walked" - a single word phrase is "unigram", a two word phrase is "bi-gram", and three word phrase is "tri-gram" etc 
    - **Stemming:** **normalizes words before counting them** - technique in which algo are applied to consolidate words before counting them - i.e. words with same root like "power", "powered", "powerful" are considered same token
    - **Vectorization:** captures **semantic relatioships between word** by assigning them to locations in n-dimensional space

- **Frequency analysis:** After tokenization, **count no. of occurences of each token** - **Term frequency** - inverse document frequency (TF-IDF) - score calculated based on occurences of term -->

**NLP Services:** 

- **Text (Azure AI Language):** includes lang detection, sentiment analysis, entity recognition, entity linking, extracting key phrases, summarization, personal identifying information

<!--   - **Language detection** - returns name, langauge code and score (return **NaN** (not a number) when lang is **ambiguous**)
  - **Sentiment analysis and opinion mining** - if text +ve (1) or -ve (0)
  - **Entity recognition** return list of entities {like people, dates, times}
  - **Entity linking** - identifies **known entitites** together, **link to Wikipedia/ external websites** to disambiguate terms (entities) identified in a text
  - **Extract key phrases** - to summarize doc or find key talking points from unstructured data
  - **Summarization** - summarizing text
  - **Personal Identifying Information (PII)** - identifies **personally sensitive info**, incl **personal health info (PIH)** -->

- **Speech Detection** 
- **Translator** - only text-to-text translation
- **Language Understanding**: interpret and implement commands
- **Azure Cognitive Services**
	
<!-- **NOTE:** Any form of **text processing, analysis, or speech recognition falls under NLP** (different from **OCR** as it **only reads text from images with no processing** taking place) -->

#### [Fundamentals of Azure AI Speech - Speech Recognition and Speech Synthesis](https://learn.microsoft.com/en-in/training/modules/recognize-synthesize-speech/?WT.mc_id=cloudskillschallenge_8E1F62A7-99E3-48E4-9EC9-1FFFB99EE9AF&ns-enrollment-type=Collection&ns-enrollment-id=67pkuw8qe4j4)

- **Speech recognition** - ability to detect and interpret spoken input - convert **speech into text** (Speech Text) - spoken words can be **recorded voice, audio file, live audio** - uses models 
- **Speech synthesis** - **text-to-speech API** - generate computarized voice - e.g. GPS applications, voice menus or broadcasting announcements
 
<!--   - How it works? 
    - System **tokenizes text** and breaks down **into words**
    - Assigns **phonetic sound** to each word 
    - Then breaks phonetic transcription **into prosodic units** (such has phrases, clauses, sentences) to **create phonemes** that will be **converted to audio format**
    - Pheonemes synthesized as **audio** - assigned **particular voice, speaking rate, pitch and volume**

 -->

Services - **Azure AI Speech (own endpoint and key) and Azure Cognitive Services (1 service to rule them all)**

#### [Translate text and speech with Azure AI services](https://learn.microsoft.com/en-in/training/modules/translate-text-with-translation-service/?WT.mc_id=cloudskillschallenge_8E1F62A7-99E3-48E4-9EC9-1FFFB99EE9AF&ns-enrollment-type=Collection&ns-enrollment-id=67pkuw8qe4j4)

- **Azure AI Translator Service** provides **text-to-text** translation in single request API) - service uses Neural Machine Translation (NMT) model for translation - You can specify **from language with multiple to languages**, enabling simultaneous translation **from one source doc to multiple languages** - e.g. from spanish to english and french, "from" lang of "es", a "to" lang of "en", and another "to" lang of "fr" (~~and not "to" lang "en-fr"~~) - **Text translation and document translation**

- **Azure AI Speech Service (own endpoint and key)** provides **language identification, speaker recognition, and voice assistants** - **directly (speech-to-speech translation)** or **intermediary text format (speech-to-text format)**

<!--   - This service includes the following APIs
    - **Speech to text API**: Perform **real-time, batch transcription** (for presentation, demos etc) of **audio into text** format - model based on **Universal Language Model** trained by Microsoft 

    - **Text to speech API:** Converts input to audible speech - can specify voice to be used to vocalize the text - include pre-defined **voices** with **multiple languages** and regional pronounciation, **neural voices** - can also **develop custom voices**

    - **Speech Translation:** speech-to-speech - used to translate speech in one language to text or speech in another -->


- **Azure Cognitive Services**: 1 service to rule them all
	
<!-- These services translate **between** more than **60 languages**

**Extra optional configuration:**
- **Profanity filtering:** without any filtering, the service will translate the input text, without filtering out probability
- **Selective translation:** can tag content so that it is not translated -->

#### [Fundamentals of Conversational Language Understanding](https://learn.microsoft.com/en-in/training/modules/create-language-model-with-language-understanding/?WT.mc_id=cloudskillschallenge_8E1F62A7-99E3-48E4-9EC9-1FFFB99EE9AF&ns-enrollment-type=Collection&ns-enrollment-id=67pkuw8qe4j4)

**3 Core Concepts**: Utterances, Entities and Intent.

<!-- | Utterances                           | Entities                                    | Intent                                             |
|--------------------------------------|---------------------------------------------|----------------------------------------------------|
| A **phrase** we say to the AI system | An **item** to which the phrase/utterances refers | **Purpose or goal** of phrase                        |
| Start coffee machine                 | Coffee machine                              | Start | -->

<!-- Note: **None Intent** - to handle utterances that do not match to any intent -->

**Azure Services**
- **Azure AI Language** - under which **LUIS (Language Understanding Service)** works - standalone service that offers authoring, training and prediction

  <!-- - **Authoring:** Create entity and intent and select words in utterances - can be done in any order using Language Studio
  - **Training:** Teaching model to match natural language expression - then testing model - making updates and retraining model 
  - **Predicting:** publish/deploy - Client can access through prediction resource's endpoint and authentication key -->

- **Azure Cognitive Service** - 1 service to rule them all! (**NOTE:** This can only be used **for predictions ~~and not for authoring models~~**)

<!-- Method: Create lang resource in azure portal - create project in Language Studio - add intent_name in Schema Definition page and add min 5 utterances for an intent in Data Labelling page - then label entites - Now train the model and then deploy and test - It will provide **predicted intent, predicted entity with confidence score** -->

**Conversational AI**: 
AI systems that can chat with humans e.g. bot answering, automated responses 
**Note:** Conversational AI is only used for conversing, and is not same as NLP

**Two core services:** Azure AI Language and Azure AI Bot Service.

<!-- - **Azure AI Language (now Azure Cognitive Service for Language):** **used to create knowledge database of qs ans** - **enter manually, or import FAQ, web page or chit-chat data in PDF or DOC ~~ZIP, CSV, MP4~~** - then publish so that Azure bot service can deliver to end users - can be interacted **via REST API, software development kit, and Language studio**
- **Azure AI Bot Service:** used **to deliver knowledge database to end users** - provides framework for **developing**, **publishing**, and **managing bots** - create interface via **web chat, email, Teams, slack** etc - created via **Bot Framework SDK** or in the Language Studio for Cognitive Services for Language - **Facebook requires application to be registered with channel**
- **Azure QnA Maker:** to **create knowledge base** from **FAQ doc, websites** etc - ~~cannot be used to query SQL database~~ -->

* * *

<!-- #### [Fundamentals of Generative AI - Azure OpenAI Service](https://learn.microsoft.com/en-us/training/paths/introduction-generative-ai/)

**Generative AI** - takes natural language input and returns responses in variety of formats i.e. **natural language, images and code** - creates original content 

**Large Language Models (LLMs)**: specialized type of ml model - use deep learning to process and understand natural langauge on massive scale - can perform tasks:
- **Determining text** or **classifying natural language text**
- **Summarizing text**
- **Comparing** multiple **text** sources for semantic similarity
- **Generate new** natural language

**Tranformer model architecture** consists of two components or blocks:
- An **encoder block** that creates semantic representation of the training vocabulary - used by Bidirectional Encoder Representations from Transformers model (BERT) developed by Google
- A **decoder block** that generates new language sequences - used by Generative Tranformer (GPT) model developed by OpenAI

**Tokenization:** First step of training a transformer model is to decompose the training text into tokens with a token id

**Embeddings:** These are vectors that give relationships between tokens- multi-valued numeric representation of information - algo like Word2Vec - to represent semantic meaning of tokken i.e. each element indicates location of word along a partivular dimension, like coordinates on map 

**Attention:** technique to examine a sequence of text tokens and quantify relationships between them 

**Azure OpenAI Service**: deploy, cutomise and host large lang models - supports many models:
- **GPT-4 models**: latest generative pretrained (GPT) models - generate natural language and code
- **GPT 3.5 models**: generate natural lang and code - GPT-35-turbo optimized for chat-based interactions
- **Embedding models**: convert text into numeric vectors - for analytics scenario e.g. comparing texts for similarities
- **DALL-E models**: generate images based on natural lang prompts

**Copilots**: originates from Microsoft - features can be found through commonly used applications - Microsoft copilot is first-party and plugins developed by other companies as third-part copilots - build copilots that submit prompts and generate content to use in application - revolutionize the way we work 




* * *

- **Featurization**: collection of techniques like feature engineering, data-scaling and normalization
- **Feature Enginnering:** Process of **creating/adding** new features - **can split data**
- **Feature Selection:** Process of selecting the key subset of features - **eliminate/remove** irrelevant, redundant features (~~not help in splitting data~~) -->

















