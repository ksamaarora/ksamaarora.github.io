---
layout: post
title:  Azure AI
date:   2023-12-23 1:28:47 +05:30
tags:
  - AI
  - azure
description: Azure AI
---

### Module 1 - [Fundamental AI Concepts](https://learn.microsoft.com/en-in/training/modules/get-started-ai-fundamentals/?WT.mc_id=cloudskillschallenge_8E1F62A7-99E3-48E4-9EC9-1FFFB99EE9AF)

AI is a software that imitates human behaviours and capabilities.(MNCDKG)

| AI Type                               | Description                                           | Microsoft Azure Services                                      |
|---------------------------------------|-------------------------------------------------------|------------------------------------------------------|
| Machine Learning             | Captures relationships between data and draws conclusions          | Azure Machine Learning Studio |
| Computer Vision        | Deals with visual processing - image classification,object detection, | Azure AI Vision  |
|                           | image analysis, face detection & recognition, OCR (detect & read text in images)                                   |                                                                 |
| Natural Language Processing          | Analyzes written and spoken language and commands                    | Azure AI Language, Azure AI Speech           |
| Document Intelligence         | Manages, processes, and uses high volumes of varied data                                  | Azure AI Document Intelligence           |
| Knowledge Mining    | Extracts information from large volumes of data to create a searchable knowledge store | Azure AI Cognitive Search                                |
| Generative AI     | Creates original content in a variety of formats | Azure OpenAI service                                 |


**Challenges and Risks in AI:** Bias, Error harm, Data exposure, Inclusivity risk, Trust challenge, Liability challenge

**6 principles**: **Fairness**, **Reliability and Safety**, **Privacy and Security**, **Inclusivness** (includes all - everyone benefits regardless of physical ability, gender, ethnicity etc), **Transparency**, **Accountability** (developers should work within principles that meet legal standards)
(FRSPS ITA)

* * *

### Module 2 - [Use Automated Machine Learning in Azure Machine Learning](https://learn.microsoft.com/en-in/training/modules/use-automated-machine-learning/?WT.mc_id=cloudskillschallenge_8E1F62A7-99E3-48E4-9EC9-1FFFB99EE9AF)

Machine Learning is an AI tool that uses mathematics and statistics to create a model that can predict unknown values.
F(x)=y where x -> features and y -> labels we are trying to predict.

1) **Supervised Machine Learning**: 
Algo trained on labelled dataset (labels & features)
- **Regression** - used to predict a numerical value
- **Classification** - used to predict a category or class e.g. diabetic or not diabetic

2) **Unsupervised Machine Learning:** 
Algo trained without any predefined labels
- **Clustering** - grouping similar items together based on their features

**Other Terms:**
- **Endpoint:** the HTTP address (URL) at which service is deployed/accessed.
- **Key:** a secret value used by client applications to authenticate/prove themselves

Refer to this **Lab 1** link - [Azure Automated Machine Learning](https://microsoftlearning.github.io/AI-900-AIFundamentals/instructions/02-module-02.html)

	
**1) Select dataset**, **2) Use algorithm to train the model**

**3) Evaluate performance:**

**Cross Validation:** compare predicted value and actual value. **Residuals:** difference between the predicted and actual value (error). **R2 square:** Metric range from 0 to 1 - **for the best possible R2 score, set the primary metric to R2 score** - higher value, better model. **RMSE (Root mean squared error):** squaring errors of all test cases, finding mean of these squares, and then taking square root - smaller value, more accurate model. **NRMSE (Normalized RMSE):** standardizes the RMSE metric so it can be used for comparison between models which have variables on different scales 
	
**4) Deploy a predictive service:** Can deploy service as **ACI (Azure Container Instances)** or **AKS (Azure Kubernates Services).** 4 kinds of Compute Resources: Compute Instances, Compute Clusters, Kubernetes Clusters and Attached Compute 

* * *

### Module 3 - [Create a Regression Model with Azure Machine Learning Designer](https://learn.microsoft.com/en-in/training/modules/create-regression-model-azure-machine-learning-designer/?WT.mc_id=cloudskillschallenge_8E1F62A7-99E3-48E4-9EC9-1FFFB99EE9AF)

#### Azure Machine Learning Studio: 
To begin use of it, you need to **assign the workspace created in Azure portal to Azure Machine Learning studio**.

**Azure Automated ML:** automatically trains ML model by providing dataset and picking label i.e. **automatically pick algo** - ((DICY))allows to include **custom python script** - uses **solns without need of programming**.

**Azure Designer:** provides **drag-and-drop interface/ canvas** to train, test and deploy ML models - enables to **save progress** as a **pipeline draft** - allows **custom python & R fns ~~and not JS functions~~**.

**Azure ML Jobs:** It **executes a task** against a specified computer target and keeps a **track/run record for the job**. Each time you **run** a pipeline, the configuration of the pipeline and its **results are stored** in your workspace as a pipeline job.
	
**Pipelines:** Each **designer project**, known as pipeline, has a left panel for navigation and a canvas on your right hand side. It starts with a dataset from which you train a model. In pipeline project, you can access **data assets** and **components** from the left panels Asset Library tab. 

Refer to this **Lab 2** link - [Explore regression with Azure Machine Learning Designer](https://microsoftlearning.github.io/AI-900-AIFundamentals/instructions/02a-create-regression-model.html)

#### UNDERSTAND STEPS FOR REGRESSION:

**1) Prepare Data:** Either create **own dataset** in Azure ML Studio or **choose** from **azure storage, local files, web files, or from SQL databases**.

| **Module**                        | Function                                            |
| ----------------------------- | --------------------------------------------------- |
| Select columns in dataset     | To choose specific columns/features from dataset   |
| Clean missing data module     | To handle missing values within the dataset        |
| Normalize data module         | Changing values to be on a similar scale            |
| Split data module             | Will **randomly** split **into rows** for training and validation datasets to compare labels that model predicts to actual known labels  |
| Join data module              | Will join datasets together                         |

- When training model, **randomly split rows** into seperate subsets - to **test model** by **using data** that was **not used to train** the model.

**2) Train the Model:**

![trainmodel](https://cdn.discordapp.com/attachments/1173139022688829511/1182362931623628931/train-score.png?ex=65846c4a&is=6571f74a&hm=130c8b5c1abc03ff3bb7c923d71406d43f0eaff92aef8352ad5011b9b07c0200&)

**3) Evaluate Performance:**
	
| Metric                               | Description                                           | Interpretation                                      |
|---------------------------------------|-------------------------------------------------------|------------------------------------------------------|
| Mean Absolute Error **(MAE)**             | Avg diff between predicted and actual values          | Lower value is better; units same as values and labels |
| Root Mean Squared Error (**RMSE)**        | Larger difference indicates greater variance         | Lower value is better; units same as values and labels |
| Relative Squared Error **(RSE)**          | Range 0 to 1; Closer to 0 is better                    | Values and labels can have different units           |
| Relative Absolute Error **(RAE)**         | Closer to 0 is better                                  | Values and labels can have different units           |
| Coefficient of Determination **(R^2)**    | Summarizes difference between predicted and true values | Closer to 1 is better                                 |

**4) Deploy a predictive service:** 
	After creating the interference pipeline, you can **deploy it as an endpoint**. Deployment state can be viewed on the Details page and will indicated **healthy when deployment is complete**. On Test tab, you can test your deployed service with a sample data in **JSON format** (used to **indicate recording pattern of data**).

- Note: **Azure's indexer** is a tool that **exports incoming doc** into JSON and pushes JSON to an index for blob storage 

* * *

### Module 4 - [Create a classification model with Azure Machine Learning Designer]()

Refer to **Lab 3** link [Explore classification with Azure Machine Learning Designer](https://microsoftlearning.github.io/AI-900-AIFundamentals/instructions/02b-create-classification-model.html)

#### UNDERSTAND STEPS FOR CLASSIFICATION:
**1) Prepare Data, 2) Train Model** 
	
**3) Evaluate Performance:**

**Confusion Matrix:**
It is a tool to **assess the quality of a classification models predictions**.

![matrix](https://cdn.discordapp.com/attachments/1173139022688829511/1190696091973320854/Screenshot_2023-12-30_at_10.10.12_PM.png?ex=65a2bd26&is=65904826&hm=7a80986f4d50861cfdc8647074ffd8daa7669c656e486e98af968550cd431dd5&)

<!-- different pic (https://cdn.discordapp.com/attachments/1173139022688829511/1180000991089807430/Screenshot_2023-12-01_at_9.50.50_AM.png?ex=657bd48f&is=65695f8f&hm=ac80b2608022088e79c1fc32f43c96c6f0e7a4595f94eea27373c456c5eaa015&) -->

**True Positive:** Model correctly predicts the positive class, **True Negative:** Model correctly predicts the negative class 
	
**Metrics that can be derived from confusion matrix:**

- **Accuracy:** (TP+FP)/(TP+TN+FP+FN) -> no. of correct predictions
- **Precision:** TP/(TP+FP)
- **Recall/TPR:** Positive cases correctly identified (**relevant instances**) -> TP/(TP+FN)
- **F1 Score:** (2 x Precision x Recall)/(Precision)

**FPR** -> false + rate = FP/(FP+TN) -> no. of negative cases correctly identified

**5) Threshold & ROC v/s AUC:**

<!-- By default, a **predicted probability on or above 0.5 results in a class of prediction 1, while a prediction below this threshold means the prediction class is 0**.  -->
Designer has a **threshold slider** for reviewing how model performance would change depending on the set threshold. 

#### ROC (Receiver operation characteristic) curve and AUC(Area under curve) metric:

**- ROC Curve:** graphical representation **TPR v/s FPR** at different threshold values (ranging from 0 to 1).

**- AUC** is a **numerical measure** of the **ROC curve's performance** - area under RUC - closer to 1 better - **random guessing** is **0.5** (0.5-0.7 poor, 0.7-0.8 ok, 0.8-0.9 very good)

**6) Inference Pipelines:** In order to automate model into a service, need to create and deploy interference pipeline by first converting training pipeline into a **real-time interference pipeline**. This **removes training components** and **adds web service inputs and outputs** to handle requests. 

![deployment](https://cdn.discordapp.com/attachments/1173139022688829511/1180000992448749639/Screenshot_2023-12-01_at_9.51.37_AM.png?ex=657bd48f&is=65695f8f&hm=3a497508a08319aed1801f3fd9087392bacf28c4a594c3457e0188ba5c7840c8&)

**7) Deployment** (explained earlier)

* * *

### Module 5 - [Create a clustering model with Azure ML Designer](https://learn.microsoft.com/en-in/training/modules/create-clustering-model-azure-machine-learning-designer/?WT.mc_id=cloudskillschallenge_8E1F62A7-99E3-48E4-9EC9-1FFFB99EE9AF&ns-enrollment-type=Collection&ns-enrollment-id=67pkuw8qe4j4)

Refer to **Lab 4** link [Create a clustering model with Azure ML Designer](https://microsoftlearning.github.io/AI-900-AIFundamentals/instructions/02c-create-clustering-model.html)

#### UNDERSTAND STEPS FOR CLUSTERING:
**1) Prepare data**

**2) Train model:**
To train a clustering model, you need to apply a clustering algorithm to the data. 
**[K- Means Clustering Algorithm](https://www.youtube.com/watch?v=4b5d3muPQmA)**
groups items into numbers of clusters, or centroids i.e. 'K'. 
	
**K-Means Algorithm - How it works?**

- Initializing **K coordinates** as randomly selected points called **centroids**.
- **Plotting** and **assigning each point to its closest centroid**.
- **Moving the centroids to the middle of the points allocated** to it. **Reassigning the points to their closest centroid** after the move.
- **Repeating** steps 3 and 4 until the cluster allocations **stabilize**.

**3) Evaluate Performance:** 


| Metric                             | Description                                                                                                              |
|-------------------------------------|--------------------------------------------------------------------------------------------------------------------------|
| **Average Distance** to **Other Center**    | Distance of each point in the cluster to the centroids of all other clusters.                                            |
| Average Distance to **Cluster Center**  | Distance of each point in the cluster is to the centroid of the cluster.                                                  |
| Number of **Points**                    | The number of points assigned to the cluster.                                                                            |
| **Maximal Distance** to Cluster Center  | The maximum of the distances between each point and the centroid of that point’s cluster. If high, indicates dispersion/spread.   |

| **Silhouette** | Ratio of distance between points in same cluster and points in different clusters - closer to 1, better cluster seperation - range -1 to 1  |

![evaluate](https://cdn.discordapp.com/attachments/1173139022688829511/1180003884878528634/Screenshot_2023-12-01_at_10.02.43_AM.png?ex=657bd741&is=65696241&hm=279dd18fabd80e184da0753dca6d2990b0cead688f4878eb11fa788acb1d3fe5&)

**4) Interference Pipeline:** For interference pipeline, make following changes:
![changes](https://cdn.discordapp.com/attachments/1173139022688829511/1180003886128447558/Screenshot_2023-12-01_at_10.03.10_AM.png?ex=657bd741&is=65696241&hm=7fa3d839f13653936bab53db5a95f1e2c0103b967454458d9c5acb36288b9501&)

**5) Deployment**: (explained earlier)

#### Summary (IMPORTANT):

**Regression Model:** 
Raw Data -> Select Columns in Dataset -> Clean Missing Data -> Normalize data -> Split data & **Linear Regression** -> Train Model -> Score Model

**Classification Model:** 
Raw data -> Select Columns in Dataset -> Normalize data -> Split data & **Two-Class Logistic Regression** -> Train Model -> Score Model -> Evaluate Model

**Clustering Model:**
Raw data -> Select Columns in Dataset -> Clean Missing data -> Normaize data -> Split data & **K-Means Clustering** -> **Train Clustering Model** -> **Assign Data to Clusters** **(used to generate cluster predictions)** -> Evaluate Model

* * *

### Module 6 - [Computer Vision](https://learn.microsoft.com/en-in/training/modules/analyze-images-computer-vision/?WT.mc_id=cloudskillschallenge_8E1F62A7-99E3-48E4-9EC9-1FFFB99EE9AF)

**Computer Vision** - manipulation and analysis of pixel values in images.

Azure Services for computer vision:
- **Azure Computer Vision Read API**: Describe, tag, (brand, object, face) detect, categorize img, landmark and celeb, generate thumbnails, and detect inappropriate content
- **Azure Custom Vision**: Analayze, classify images and detect objects
- **Azure AI Face**
- **Azure AI Video**
- **Azure AI Document Intelligence / Azure Forms Recognizer**
- **Azure Cognitive Services** (includes **all services** - uses only **one endpoint and key** - can be used for **both training and prediction**)

**Abilities of Computer Vision:** IMP
	1) **Describe Images:** Short phrases/ sentences describe the image - confidence number between 0 to 1 - sorted in descending order based on confidence 
	2) **Tagging:** suggests key terms/ tags for an image
	3) **Object Detection:** and **bounding box** (indicate location)
	4) **Brand Detection:**, confidence score and a bounding box
	5) **Facial Detection:** and not Facial Recognition - i.e. it simply determines if there is a face, the age and a bounding box
	6) **Categorize Images:** based on 86 pre-defined categories
	7) **Landmarks and Celebrities:** and a confidence score
	8) **OCR/ Reading text from picture**
	9) **Generate thumbnails**
	10) **Detect images** with adult content, violent content or gory scenes

[Refer to **6A** Analyze image in Azure AI Vision](https://microsoftlearning.github.io/mslearn-ai-fundamentals/Instructions/Labs/03-image-analysis.html)

**Azure AI Custom Vision:** 

Image recognition service to build, deploy and improve **your own image identifier model** - **you provide your own data to train model** - can specify **whether used for training, prediction or both**

[Refer to **6B** Classify images with Azure AI Custom Vision](https://learn.microsoft.com/en-in/training/modules/classify-images-custom-vision/?WT.mc_id=cloudskillschallenge_8E1F62A7-99E3-48E4-9EC9-1FFFB99EE9AF)

<!-- Create new project - enter req credentials - add images and add tags to those images - upload the training model and evaluate - select a random image and check that tag and probability for that image  -->

1) **Model Training:** **Upload** images - train - **label/tag** them

2) **Model Evaluation:** Trained on basis of **3** evaluation **metrics**: 
- **Precision:** measures **accuracy of +ve predictions** e.g. model predicted 10 oranges of which 8 are correct -> precision=0.8 (80%)
- **Recall:** models ability to **identify relevant instances** e.g. 10 apple images and model detects 7 -> recall = 0.7 (70%)
- **Average Precision (AP):** An overall metric that accounts **both precision and recall**.

**Publishing Model:**
When publishing, **assign name** (**IterationX** where **X** is **no.** of times you have **trained** the model).
To use model, client needs these info 
- **Project ID**
- **Model Name**
- **Prediction (REST) endpoint**: HTTP address of the endpoint for prediction resource (not training resource)
- **Prediction key**: **authentication** key for prediction resource (not training resource)

[Refer to **6C** Detect Objects with Azure AI Custom Vision](https://learn.microsoft.com/en-in/training/modules/detect-objects-images-custom-vision/?WT.mc_id=cloudskillschallenge_8E1F62A7-99E3-48E4-9EC9-1FFFB99EE9AF&ns-enrollment-type=Collection&ns-enrollment-id=67pkuw8qe4j4)

**Object Detection:** **class label, probability and bounding box**

#### [Fundamentals of Facial Recognition](https://learn.microsoft.com/en-in/training/modules/detect-analyze-faces/?WT.mc_id=cloudskillschallenge_8E1F62A7-99E3-48E4-9EC9-1FFFB99EE9AF&ns-enrollment-type=Collection&ns-enrollment-id=67pkuw8qe4j4)

**To detect faces** in Vision Studio, first **make face resource in Azure AI Vision** and the **upload** and **analyze** photos.

**Azure Services:**
- **Azure AI Vision**: face detection, analysis, bounding box
- **Azure AI Video**: detect and identify faces in video
- **Azure AI Face**: offers pre-built algos that can detect, recognize, and analyze faces - returns **set of coordinates for each face**, a **rect bounding box** 
- **Azure Cognitive Services**: The one service to rule them all!

**Features:**
Can **identify accessories**, **blurred**, **exposure** (over exposed/under exposed), **glasses**, **head pose** (pitch, roll, yaw), **mask**, **noise**, **occlusion** (if objects are blocking face)
Additional Capabilities (**submit in-take form and get approval**)- **compare faces** for similarity, **identify name** of individual 

**Noise** - refers to **visual noise** in image - **high ISO setting for darker environments**:

- **Best results** are obtained when **faces are full-frontal** or near to that.
- **Shutter speed** applies to video more than images however, **faster** shutter speeds tend to create a **sharper image**, which is beneficial to facial detection

#### [Fundamentals of Optical Character Recognition](https://microsoftlearning.github.io/mslearn-ai-fundamentals/Instructions/Labs/05-ocr.html)


**Azure AI Vision service** - extract text from images - one of the **service is Read API** (**OCR engine** that **extracts text** (**page size**, **orientation**, **lines of text** on page, **words** in line of text incl. **bounding box** and text) from images, pdfs, TIFF files) and **organizes it by page and line**

Azure Services:
- **Azure AI Vision** - to track utilization and costs for AI Vision resource separately - **for image analysis**
- **Azure AI Language** - for **text analytics**
- **Azure AI Cognitive Services** - include Azure AI Vision and many other services - **used when** want to **simplify administration and deployment**


#### [Fundamentals of Azure AI Document Intelligence](https://learn.microsoft.com/en-in/training/modules/analyze-receipts-form-recognizer/?WT.mc_id=cloudskillschallenge_8E1F62A7-99E3-48E4-9EC9-1FFFB99EE9AF&ns-enrollment-type=Collection&ns-enrollment-id=67pkuw8qe4j4)

**Azure AI Document Intelligence/ Azure Forms Recognizer service**: best way to **read text from images** of **reciepts, invoices and forms** as it automatically matches the fields to values

**Features grouped by model type:**

**Prebuilt model:** the **max file size** is **50 MB** - built to **process common document** such as invoices, receipts, forms, business cards, ID documents - **identify text and extract text**, **key-value pairs**, tables, and **structures from forms and documents**, **confidence level**

**Receipt model** - trained to **recognize data** on **several receipt types** e.g. thermal receipts, hotel, gas, credit card receipts etc.

<!-- **Fields recognized** include:
- Name, address, and telephone number of the merchant
- Date and time of the purchase
- Name, quantity, and price of each item purchased
- Total, subtotals, and tax values -->

**Custom models** - can be trained to identify specific fields not included in prebuilt models

**Document analysis** - returns structured data representations, incl regions of interest and inter-relationships

**To use receipt analyzer service** in Azure AI Document Intelligence, **first create** an **azure AI Document Intelligence Resource**

### Module 7 - [Natural Language Processing](https://learn.microsoft.com/en-in/training/modules/build-faq-chatbot-qna-maker-azure-bot-service/?WT.mc_id=cloudskillschallenge_8E1F62A7-99E3-48E4-9EC9-1FFFB99EE9AF&ns-enrollment-type=Collection&ns-enrollment-id=67pkuw8qe4j4)

**Process to make bot:**
- First **make Language resource** - **use Language Studio's custom qs ans feature** - **qs ans** can be generated by **importing** an existing **FAQ doc/ web page** or **entered manually** with additional manual entries - **save it**. 
- **After created and deployed a knowledge base**, you can **deliver** it to users through a bot - create **custom bot** using **Microsoft Bot Framework SDK** ( writes code - integrates with knowledge base) 

#### [Fundamentals of Text Analysis with the Language Service](https://learn.microsoft.com/en-in/training/modules/analyze-text-with-text-analytics-service/?WT.mc_id=cloudskillschallenge_8E1F62A7-99E3-48E4-9EC9-1FFFB99EE9AF&ns-enrollment-type=Collection&ns-enrollment-id=67pkuw8qe4j4)

**NLP Services:** (TSTLA)

- **Text Analytics:** includes **language detection** (return **NaN** when lang is **ambiguous**, **sentiment analysis** - if text +ve (1) or -ve (0), **extract key phrases** (to summarize doc or find key talking points), **entity recognition** (return list of entities, categories {like people, dates, times, URLs}, confidence score)
- **Speech Detection**
- **Translator** - only text-to-text translation
- **Language Understanding**: interpret and implement commands
- **Azure Cognitive Services**
	
**NOTE:** Any form of **text processing, analysis, or speech recognition falls under NLP** (different from **OCR** as it **only reads text from images with no processing** taking place)

#### [Fundamentals of Azure AI Speech - Speech Recognition and Speech Synthesis](https://learn.microsoft.com/en-in/training/modules/recognize-synthesize-speech/?WT.mc_id=cloudskillschallenge_8E1F62A7-99E3-48E4-9EC9-1FFFB99EE9AF&ns-enrollment-type=Collection&ns-enrollment-id=67pkuw8qe4j4)

- **Speech recognition** - ability to detect and interpret spoken input - convert **speech into text** (Speech Text)
- **Speech synthesis** - **text-to-speech API** - generate computarized voice - e.g. GPS applications, voice menus or broadcasting announcements

Services - **Azure AI Speech (own endpoint and key) and Azure Cognitive Services (1 service to rule them all)**

#### [Translate text and speech with Azure AI services](https://learn.microsoft.com/en-in/training/modules/translate-text-with-translation-service/?WT.mc_id=cloudskillschallenge_8E1F62A7-99E3-48E4-9EC9-1FFFB99EE9AF&ns-enrollment-type=Collection&ns-enrollment-id=67pkuw8qe4j4)

- **Azure AI Translator Service** provides **text-to-text** translation in single request API) - service uses Neural Machine Translation (NMT) model for translation - You can specify **from language with multiple to languages**, enabling simultaneous translation **from one source doc to multiple languages** - e.g. from spanish to english and french, "from" lang of "es", a "to" lang of "en", and another "to" lang of "fr" (~~and not "to" lang "en-fr"~~)

- **Azure AI Speech Service (own endpoint and key)** provides speech translation - **directly (speech-to-speech translation)** or **intermediary text format (speech-to-text format)**
  - This service includes the following APIs
    - **Speech to text API**: Perform **real-time, batch transcription** (for presentation, demos etc) of **audio into text** format - model based on **Universal Language Model** trained by Microsoft 

    - **Text to speech API:** Converts input to audible speech - can specify voice to be used to vocalize the text - include pre-defined voices with multiple languages and regional pronounciation - can also develop custom voices and use them 

    - **Speech Translation:** speech-to-speech - used to translate speech in one language to text or speech in another


- **Azure Cognitive Services**: 1 service to rule them all
	
These services translate **between** more than **60 languages**

**Extra optional configuration:**
- **Profanity filtering:** without any filtering, the service will translate the input text, without filtering out probability
- **Selective translation:** can tag content so that it is not translated

#### [Fundamentals of Conversational Language Understanding](https://learn.microsoft.com/en-in/training/modules/create-language-model-with-language-understanding/?WT.mc_id=cloudskillschallenge_8E1F62A7-99E3-48E4-9EC9-1FFFB99EE9AF&ns-enrollment-type=Collection&ns-enrollment-id=67pkuw8qe4j4)

**3 Core Concepts**:

| Utterances                           | Entities                                    | Intent                                             |
|--------------------------------------|---------------------------------------------|----------------------------------------------------|
| A **phrase** we say to the AI system | An **item** to which the phrase/utterances refers | **Purpose or goal** of phrase                        |
| Start coffee machine                 | Coffee machine                              | Start |

**Azure Services**
- **Azure AI Language** - under which **LUIS (Language Understanding Service)** works - standalone service that offers authoring, training and prediction

  - **Authoring:** Create entity and intent and select words in utterances - can be done in any order using Language Studio
  - **Training:** Teaching model to match natural language expression - then testing model - making updates and retraining model 
  - **Predicting:** publish/deploy - Client can access through prediction resource's endpoint and authentication key

- **Azure Cognitive Service** - 1 service to rule them all! (**NOTE:** This can only be used **for predictions ~~and not for authoring models~~**)

Method: Create lang resource in azure portal - create project in Language Studio - add intent_name in Schema Definition page and add min 5 utterances for an intent in Data Labelling page - then label entites - Now train the model and then deploy and test - It will provide **predicted intent, predicted entity with confidence score**

**Conversational AI**: 
AI systems that can chat with humans e.g. bot answering, automated responses 
**Note:** Conversational AI is only used for conversing, and is not same as NLP

**Two core services:**

- **Azure AI Language (now Azure Cognitive Service for Language):** **used to create knowledge database of qs ans** - enter manually, or import FAQ or chit-chat data - then publish so that Azure bot service can deliver to end users - can be interacted **via REST API, software development kit, and Language studio**
- **Azure AI Bot Service:** used **to deliver knowledge database to end users** - provides framework for **developing**, **publishing**, and **managing bots** - create interface via **web chat, email, Teams, slack** etc - created via **Bot Framework SDK** or in the Language Studio for Cognitive Services for Language 
- **Azure QnA Maker:** to **create knowledge base** from **FAQ doc, websites** etc - ~~cannot be used to query SQL database~~

* * *

- **Feature Enginnering:** Process of **creating/adding** new features
- **Feature Selection:** Process of selecting the key subset of features - **eliminate/remove** irrelevant, redundant features (~~not help in splitting data~~)

























