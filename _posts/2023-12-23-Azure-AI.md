---
layout: post
title:  Azure AI
date:   2023-12-23 1:28:47 +05:30
tags:
  - AI
  - azure
description: Azure AI
---

<!-- <figure>
<img src="{{ page.image }}" alt="ilustrasi repo yang mau diupdate">
<figcaption>Fig 1. Gambaran ribetnya.</figcaption>
</figure> -->

### Module 1 - [Fundamental AI Concepts](https://learn.microsoft.com/en-in/training/modules/get-started-ai-fundamentals/?WT.mc_id=cloudskillschallenge_8E1F62A7-99E3-48E4-9EC9-1FFFB99EE9AF)

AI is a software that imitates human behaviours and capabilities.(MNCDKG)

<!-- **1. Machine Learning:**
It is an area of AI that captures relationship between data and draws conclusions. 
Services in Microsoft Azure: **Azure Machine Learning Studio** 

**2. Computer Vision**
It is an area of AI that delas with **visual processing**. Services in Microsoft Azure: **Azure AI Vision**
- Image Classification
- Object Detection
- Semantic Segmentation: individual pixels are classified according to the object to which they belong
- Image analysis
- Face detection, analysis and recognition
- Optical character recognition (OCR): detect and read text in images
	
**3) Natural Language Processing**
It is an area of AI that deals with creating software that analyse **written and spoken language and commands**. 
NLP in Microsoft Azure: **Azure AI Language and Azure AI Speech**

**4) Document Intelligence**
It is an area of AI that deals with **managing,** **processing** and using **high volumes** of variety of **data**.
Services in Microsoft Azure: **Azure AI Document Intelligence**

**5) Knowledge Mining**
Capabilities within AI to **extract info from large volumes of data** to create searchable knowledge store 
Services in Microsoft Azure: **Azure AI Cognitive Search**
	
**6) Generative AI**
Capabilities within AI that **creates original content in variety of formats**
Services in Microsoft Azure: **Azure OpenAI service** -->

| AI Type                               | Description                                           | Microsoft Azure Services                                      |
|---------------------------------------|-------------------------------------------------------|------------------------------------------------------|
| Machine Learning             | Captures relationships between data and draws conclusions          | Azure Machine Learning Studio |
| Computer Vision        | Deals with visual processing - image classification,object detection, | Azure AI Vision  |
|                           | image analysis, face detection & recognition, OCR (Optical Character Recognition)                                   |                                                                 |
| Natural Language Processing          | Analyzes written and spoken language and commands                    | Azure AI Language, Azure AI Speech           |
| Document Intelligence         | Manages, processes, and uses high volumes of varied data                                  | Azure AI Document Intelligence           |
| Knowledge Mining    | Extracts information from large volumes of data to create a searchable knowledge store | Azure AI Cognitive Search                                |
| Generative AI     | Creates original content in a variety of formats | Azure OpenAI service                                 |

(OCR): detect and read text in images


**Challenges and Risks in AI:** Bias, Error harm, Data exposure, Inclusivity risk, Trust challenge, Liability challenge


At Microsoft, AI software development is guided by **6 principles**: **Fairness**, **Reliability and Safety**, **Privacy and Security**, **Inclusivness** (everyone benefit regardless of physical ability, gender, ethnicity etc), **Transparency**, **Accountability** (developers should work within principles that meet legal standards)
(FRSPS ITA)

### Module 2 - [Use Automated Machine Learning in Azure Machine Learning](https://learn.microsoft.com/en-in/training/modules/use-automated-machine-learning/?WT.mc_id=cloudskillschallenge_8E1F62A7-99E3-48E4-9EC9-1FFFB99EE9AF)

Machine Learning is an AI tool that uses mathematics and statistics to create a model that can predict unknown values.
F(x)=y where x -> features and y -> labels we are trying to predict.

1) **Supervised Machine Learning**: 
Algo trained on labelled dataset (labels & features)
- Regression - used to predict a numerical value
- Classification - used to predict a category or class e.g. diabetic or not diabetic

2) **Unsupervised Machine Learning:** 
Algo trained without any predefined labels
- Clustering - grouping similar items together based on their features

Refer to this **Lab 1** link - [Azure Automated Machine Learning](https://microsoftlearning.github.io/AI-900-AIFundamentals/instructions/02-module-02.html)

	
**1) Select dataset**
<!-- Either create own dataset in Azure ML Studio or choose from azure storage, local files, web files, or from SQL databases. -->
	
**2) Use algorithm to train the model**

**3) Evaluate performance:**

**Cross Validation:** compare predicted value and actual value. **Residuals:** difference between the predicted and actual value (error). **R2 square:** Metric range from 0 to 1 - for the best possible R2 score, set the primary metric to R2 score - higher value, better model. **RMSE (Root mean squared error):** squaring errors of all test cases, finding mean of these squares, and then taking square root - smaller value, more accurate model. **NRMSE (Normalized RMSE):** standardizes the RMSE metric so it can be used for comparison between models which have variables on different scales 
	
**4) Deploy a predictive service:** Can deploy service as **ACI (Azure Container Instances)** or **AKS (Azure Kubernates Services).** 4 kinds of Compute Resources: Compute Instances, Compute Clusters, Kubernetes Clusters and Attached Compute

**Azure AI Services are based on three principles** - Prevuilt and ready to use, Accessed through APIs, available on Azure. 

### Module 3 - [Create a Regression Model with Azure Machine Learning Designer](https://learn.microsoft.com/en-in/training/modules/create-regression-model-azure-machine-learning-designer/?WT.mc_id=cloudskillschallenge_8E1F62A7-99E3-48E4-9EC9-1FFFB99EE9AF)

#### Azure Machine Learning Studio: 
To begin use of it, you need to **assign the workspace created in Azure portal to Azure Machine Learning studio**.

**Azure Designer:** Used to train, test and deploy machine learning models. You can use Designer to author regression pipelines with a **drag-and-drop interface**.

**Datasets:** You can create data assets on the Data page from local files, a datastore, web files, and open Datasets, these datasets will appear along with standard sample datasets in designers Asset Library. 

<!-- ![data](https://cdn.discordapp.com/attachments/1173139022688829511/1179381664108007434/Screenshot_2023-11-29_at_4.49.31_PM.png?ex=657993c4&is=65671ec4&hm=0845ebd1fddbac537637d561d81537395b039538fa5149a30b382e1395633407&) -->

**Azure ML Jobs:** It executes a task against a specified computer target and keeps a track/run record for the job. Each time you run a pipeline, the configuration of the pipeline and its results are stored in your workspace as a pipeline job.
	
**Pipelines:** Each designer project, known as pipeline, has a left panel for navigation and a canvas on your right hand side. It starts with a dataset from which you train a model. In pipeline project, you can access **data assets** and **components** from the left panels Asset Library tab. 

<!-- ![pipeline](https://cdn.discordapp.com/attachments/1173139022688829511/1179381664489672704/Screenshot_2023-11-29_at_4.49.49_PM.png?ex=657993c4&is=65671ec4&hm=4544f6f6e5114c270ecee0aa407cfc388e962f3ab8e54752fe3a7e0691649a77&) -->

Refer to this **Lab 2** link - [Explore regression with Azure Machine Learning Designer](https://microsoftlearning.github.io/AI-900-AIFundamentals/instructions/02a-create-regression-model.html)

#### UNDERSTAND STEPS FOR REGRESSION:

**1) Prepare Data:** Either create **own dataset** in Azure ML Studio or **choose** from **azure storage, local files, web files, or from SQL databases**. Make dataset - use **pre-built components** - these components enable to **clean data**, **normalize features**, **join tables** and more. **Normalization:** Changing values to be on similar scale. 
	
**2) Train the Model:**

![trainmodel](https://cdn.discordapp.com/attachments/1173139022688829511/1182362931623628931/train-score.png?ex=65846c4a&is=6571f74a&hm=130c8b5c1abc03ff3bb7c923d71406d43f0eaff92aef8352ad5011b9b07c0200&)

**3) Evaluate Performance:**
<!-- ![evaluation](https://cdn.discordapp.com/attachments/1173139022688829511/1179381665341116416/Screenshot_2023-11-29_at_4.50.11_PM.png?ex=657993c4&is=65671ec4&hm=3973c8e584ebf5688575c162764ca98f613523c366247f2f8a1f2fa2db5fafa8&) -->
	
| Metric                               | Description                                           | Interpretation                                      |
|---------------------------------------|-------------------------------------------------------|------------------------------------------------------|
| Mean Absolute Error (MAE)             | Avg diff between predicted and actual values          | Lower value is better; units same as values and labels |
| Root Mean Squared Error (RMSE)        | Larger difference indicates greater variance         | Lower value is better; units same as values and labels |
| Relative Squared Error (RSE)          | Range 0 to 1; Closer to 0 is better                    | Values and labels can have different units           |
| Relative Absolute Error (RAE)         | Closer to 0 is better                                  | Values and labels can have different units           |
| Coefficient of Determination (R^2)    | Summarizes difference between predicted and true values | Closer to 1 is better                                 |

<!-- **- Mean Absolute Error (MAE):** Avg diff between predicted and actual values - lower value, better model - value and label have same units
	
**- Root Mean Squared Error (RMSE):** When compared to MAE, a larger difference indicates greater variance in the individual errors - value and labels have same units

**- Relative Squared Error (RSE):** Range 0 to 1 - Closer to 0, better model, values and labels can have diff units
	
**- Relative Absolute Error (RAE):** Closer to 0, better the model, values and labels have diff units
	
**- Coefficient of Determination (R^2) / R Squared:** 
Summarizes how much difference between predicted and true values. Closer to 1, better model -->

**4) Deploy a predictive service:** 
	After creating the interference pipeline, you can deploy it as an endpoint. Deployment state can be viewed on the Details page and will indicated Healthy when deployment is complete. On Test tab, you can test your deployed service with a sample data in JSON format. You can find credentials for your service on Consume tab. 

### Module 4 - [Create a classification model with Azure Machine Learning Designer]()

Refer to **Lab 3** link [Explore classification with Azure Machine Learning Designer](https://microsoftlearning.github.io/AI-900-AIFundamentals/instructions/02b-create-classification-model.html)

#### UNDERSTAND STEPS FOR CLASSIFICATION:
**1) Prepare Data, 2) Train Model** 

<!-- **2) Train Model:** Create a pipeline - input datasets modules and then save and run the pipeline (in the runtime settings - select compute cluster) -->

<!-- ![trainmodel](https://cdn.discordapp.com/attachments/1173139022688829511/1180000990464843886/Screenshot_2023-12-01_at_9.50.20_AM.png?ex=657bd48f&is=65695f8f&hm=c178adf5a45cd257e040621916bc395d556bf9539f47905abda855084e6e6a9e&) -->
	
**3) Evaluate Performance:**

<!-- ![evaluate](https://cdn.discordapp.com/attachments/1173139022688829511/1180000990771036271/Screenshot_2023-12-01_at_9.50.31_AM.png?ex=657bd48f&is=65695f8f&hm=44d573c24c2715089f8678f4940bc7f6b71860cf62407b6ce15a963206c812b2&) -->

**Confusion Matrix:**
It is a tool to **assess the quality of a classification models predictions**.

![matrix](https://cdn.discordapp.com/attachments/1173139022688829511/1180000991089807430/Screenshot_2023-12-01_at_9.50.50_AM.png?ex=657bd48f&is=65695f8f&hm=ac80b2608022088e79c1fc32f43c96c6f0e7a4595f94eea27373c456c5eaa015&)
	

<!-- ![matrixdetails](https://cdn.discordapp.com/attachments/1173139022688829511/1180000991442116668/Screenshot_2023-12-01_at_9.51.02_AM.png?ex=657bd48f&is=65695f8f&hm=ad3cc83b7f96bac161e12e14cb74b0b993c4fecb288e67ca67fc1c7b270edf4d&) -->
	
**Metrics that can be derived from confusion matrix:**

- **Accuracy:** (TP+FP)/(TP+TN+FP+FN) -> no. of correct predictions
- **Precision:** TP/(TP+FP)
- **Recall/TPR:** Positive cases correctly identified -> TP/(TP+FN)
- **F1 Score:** (2 x Precision x Recall)/(Precision)

**FPR** -> false + rate = FP/(FP+TN) -> no. of negative cases correctly identified

**5) Choosing a threshold:**

By default, a **predicted probability on or above 0.5 results in a class of prediction 1, while a prediction below this threshold means the prediction class is 0**. Designer has a threshold slider for reviewing how model performance would change depending on the set threshold. 

<!-- ![threshold](https://cdn.discordapp.com/attachments/1173139022688829511/1180000991895109662/Screenshot_2023-12-01_at_9.51.15_AM.png?ex=657bd48f&is=65695f8f&hm=b62d1732f5f73cac06f51e32cbad994f551a8ad8e82344f69c431dce831ba19f&) -->

#### ROC (Receiver operation characteristic) curve and AUC(Area under curve) metric:

**- ROC Curve:** graphical representation **TPR v/s FPR** at different threshold values (ranging from 0 to 1).

**- AUC** is a **numerical measure** of the **ROC curve's performance**, ranging from 0 to 1. **Random guessing** ROC curve yields **AUC of 0.5**. **AUC>0.5** means **model better** than random guessing.

<!-- ![ROC](https://cdn.discordapp.com/attachments/1173139022688829511/1180005066485288980/Screenshot_2023-12-01_at_10.08.34_AM.png?ex=657bd85b&is=6569635b&hm=7fc2b3ab244eafecd8f9b400fc8862e149a78e9231e249b5e939dc65d0ccc8db&) -->

**6) Inference Pipelines:** In order to automate model into a service, need to create and deploy interference pipeline by first converting training pipeline into a **real-time interference pipeline**. This **removes training components** and **adds web service inputs and outputs** to handle requests. 

![deployment](https://cdn.discordapp.com/attachments/1173139022688829511/1180000992448749639/Screenshot_2023-12-01_at_9.51.37_AM.png?ex=657bd48f&is=65695f8f&hm=3a497508a08319aed1801f3fd9087392bacf28c4a594c3457e0188ba5c7840c8&)

**7) Deployment** (explained earlier)

### Module 5 - [Create a clustering model with Azure ML Designer](https://learn.microsoft.com/en-in/training/modules/create-clustering-model-azure-machine-learning-designer/?WT.mc_id=cloudskillschallenge_8E1F62A7-99E3-48E4-9EC9-1FFFB99EE9AF&ns-enrollment-type=Collection&ns-enrollment-id=67pkuw8qe4j4)

Refer to **Lab 4** link [Create a clustering model with Azure ML Designer](https://microsoftlearning.github.io/AI-900-AIFundamentals/instructions/02c-create-clustering-model.html)

#### UNDERSTAND STEPS FOR CLUSTERING:
**1) Prepare data**

**2) Train model:**
To train a clustering model, you need to apply a clustering algorithm to the data. 
**[K- Means Clustering Algorithm](https://www.youtube.com/watch?v=4b5d3muPQmA)**
groups items into numbers of clusters, or centroids i.e. 'K'. 
	
**K-Means Algorithm - How it works?**

- Initializing **K coordinates** as randomly selected points called **centroids**.
- **Plotting** and **assigning each point to its closest centroid**.
- **Moving the centroids to the middle of the points allocated** to it. **Reassigning the points to their closest centroid** after the move.
- **Repeating** steps 3 and 4 until the cluster allocations **stabilize**.

**3) Evaluate Performance:** 


| Metric                             | Description                                                                                                              |
|-------------------------------------|--------------------------------------------------------------------------------------------------------------------------|
| Average Distance to Other Center    | Distance of each point in the cluster to the centroids of all other clusters.                                            |
| Average Distance to Cluster Center  | Distance of each point in the cluster is to the centroid of the cluster.                                                  |
| Number of Points                    | The number of points assigned to the cluster.                                                                            |
| Maximal Distance to Cluster Center  | The maximum of the distances between each point and the centroid of that point’s cluster. If high, indicates dispersion/spread.   |

| Silhouette | Ratio of distance between points in same cluster and points in different clusters - closer to 1, better cluster seperation - range -1 to 1  |

![evaluate](https://cdn.discordapp.com/attachments/1173139022688829511/1180003884878528634/Screenshot_2023-12-01_at_10.02.43_AM.png?ex=657bd741&is=65696241&hm=279dd18fabd80e184da0753dca6d2990b0cead688f4878eb11fa788acb1d3fe5&)

<!-- **The metrics in each row are:**

- **Average Distance to Other Center:** Distance of each point in the cluster to the centroids of all other clusters.
- **Average Distance to Cluster Center:** Distance of each point in the cluster is to the centroid of the cluster.
- **Number of Points:** The number of points assigned to the cluster.
- **Maximal Distance to Cluster Center:** The maximum of the distances between each point and the centroid of that point’s cluster. If this number is high, the cluster may be widely dispersed. Helps determine the cluster’s spread. -->

**4) Interference Pipeline:** For interference pipeline, make following changes:
![changes](https://cdn.discordapp.com/attachments/1173139022688829511/1180003886128447558/Screenshot_2023-12-01_at_10.03.10_AM.png?ex=657bd741&is=65696241&hm=7fa3d839f13653936bab53db5a95f1e2c0103b967454458d9c5acb36288b9501&)

<!-- ![interference](https://cdn.discordapp.com/attachments/1173139022688829511/1180003885692244028/Screenshot_2023-12-01_at_10.02.55_AM.png?ex=657bd741&is=65696241&hm=1e78c4be6c0589e20a8b655f13a07e03022db4f8282f52db8391e9a608cc815e&) -->

**5) Deployment**: (explained earlier)

#### Summary:

**Regression Model:** 
Raw Data -> Select Columns in Dataset -> Clean Missing Data -> Normalize data -> Split data & **Linear Regression** -> Train Model -> Score Model

**Classification Model:** 
Raw data -> Select Columns in Dataset -> Normalize data -> Split data & **Two-Class Logistic Regression** -> Train Model -> Score Model -> Evaluate Model

**Clustering Model:**
Raw data -> Select Columns in Dataset -> Clean Missing data -> Normaize data -> Split data & **K-Means Clustering** -> **Train Clustering Model** -> **Assign Data to Clusters** **(used to generate cluster predictions)** -> Evaluate Model


### Module 6 - [Computer Vision](https://learn.microsoft.com/en-in/training/modules/analyze-images-computer-vision/?WT.mc_id=cloudskillschallenge_8E1F62A7-99E3-48E4-9EC9-1FFFB99EE9AF)

**Computer Vision** - manipulation and analysis of pixel values in images.

<!-- Services -**Azure AI vision** and **Azure AI language**  -->

**Features of AI vision:** 
**Object detection** with **bounding box**, **Visual Tags**, **Dense Captions**.

Azure Services for computer vision:
- **Azure Computer Vision:** Interact with the service via API endpoint and key
- **Azure Cognitive Services** (it includes all other AI services including Computer vision)

<!-- **Standalone v/s Cognitive Services**
- Standalone Services - used when u don’t plan to use other services and u want to track utilization and costs for Computer Vision separately
- Cognitive Services - when u want to use multiple AI services with only 1 resource - simplify administration with a single endpoint and key  -->

|                       | **Standalone Services**                                  | **Cognitive Services** Services                                |
|-----------------------|-----------------------------------------------------|----------------------------------------------------|
| **Use Case**          | Used when not planning to use other services.        | Ideal for utilizing multiple AI services together.|
| **Tracking**          | Tracks utilization and costs for Computer Vision separately. | Simplifies administration with a single endpoint and key.|
| **Resource Management**| Managed independently for each standalone service.   | Single resource for multiple AI services.          |



<!-- | **Administration**    | Requires separate management for each service.      | Streamlines administration with a unified endpoint and key.| -->


**Abilities of Computer Vision:**
	1) **Describe Images:** Short phrases/ sentences describe the image - confidence number between 0 to 1 - sorted in descending order based on confidence 
	2) **Tagging:** suggests key terms/ tags for an image
	3) **Object Detection:** and bounding box 
	4) **Brand Detection:**, confidence score and a bounding box
	5) **Facial Detection:** and not Facial Recognition - i.e. it simply determines if there is a face, the age and a bounding box
	6) **Categorize Images:** based on 86 pre-defined categories
	7) **Landmarks and Celebrities:** and a confidence score
	8) **OCR/ Reading text from picture**
	9) **Generate thumbnails**
	10) **Detect images** with adult content, violent content or gory scenes

[Refer to **6A** Analyze image in Azure AI Vision](https://microsoftlearning.github.io/mslearn-ai-fundamentals/Instructions/Labs/03-image-analysis.html)


**Azure AI Custom Vision:** Service for building image classification models - have option to create training resource, prediction resource or both - Can create a training resource, a prediction resource (i.e. Cognitive Service - one endpoint each) or both - when created for both - 2 keys and endpoints each for both resources (Standalone Service)

**Endpoint:** the HTTP address (URL) at which service is deployed/accessed.

**Key:** a secret value used by client applications to authenticate/prove themselves

[Refer to **6B** Classify images with Azure AI Custom Vision](https://learn.microsoft.com/en-in/training/modules/classify-images-custom-vision/?WT.mc_id=cloudskillschallenge_8E1F62A7-99E3-48E4-9EC9-1FFFB99EE9AF)

<!-- Create new project - enter req credentials - add images and add tags to those images - upload the training model and evaluate - select a random image and check that tag and probability for that image  -->

1) **Model Training:** Upload images to your training resource and label them with appropriate labels - repeatedly trains the model using some images and holds some back to evaluate the model

2) **Model Evaluation:** Trained on basis of **3** evaluation **metrics**: 
- **Precision** measures **accuracy of +ve predictions** e.g. model predicted 10 oranges of which 8 are correct -> precision=0.8 (80%)
- **Recall:** models ability to **identify relevant instances** e.g. 10 apple images and model detects 7 -> recall = 0.7 (70%)
- **Average Precision (AP):** An overall metric that accounts **both precision and recall**.

**Publishing Model:**
When publishing, **assign name** (**IterationX** where **X** is **no.** of times you have **trained** the model).
To use model, client needs these info 
- **Project ID**
- **Model Name**
- **Prediction endpoint**: HTTP address of the endpoint for prediction resource (not training resource)
- **Prediction key**: authentication key for prediction resource (not training resource)

[Refer to **6C** Detect Objects with Azure AI Custom Vision](https://learn.microsoft.com/en-in/training/modules/detect-objects-images-custom-vision/?WT.mc_id=cloudskillschallenge_8E1F62A7-99E3-48E4-9EC9-1FFFB99EE9AF&ns-enrollment-type=Collection&ns-enrollment-id=67pkuw8qe4j4)

**Object Detection:** **class** of each object specified, **probability score** of object, **bounding box**, **threshold value** (Shows bounding boxes of only those above that threshold value)

**Azure AI Custom Vision:** **3 tasks**
- **Upload** and **tag** images 
- **Train** the model
- **Publish** the trained model for client use


#### [Fundamentals of Facial Recognition](https://learn.microsoft.com/en-in/training/modules/detect-analyze-faces/?WT.mc_id=cloudskillschallenge_8E1F62A7-99E3-48E4-9EC9-1FFFB99EE9AF&ns-enrollment-type=Collection&ns-enrollment-id=67pkuw8qe4j4)

**Azure Services:**
- **Azure AI Vision**: face detection, analysis, bounding box
- **Azure AI Video**: detect and identify faces in video
- **Azure AI Face**: offers pre-built algos that can detect, recognize, and analyze faces - has its own endpoint and key
- **Azure Cognitive Services**: The one service to rule them all! Includes many other services as well

**Features:**
Can **identify accessories**, **blurred**, **exposure** (over exposed/under exposed), **glasses**, **head pose** (pitch, roll, yaw), **mask**, **noise**, **occlusion** (if objects are blocking face)
Additional Capabilities (**submit in-take form and get approval**)- **compare faces** for similarity, **identify name** of individual 

**Noise** - refers to **visual noise** in image - **high ISO setting for darker environments**:

- **Best results** are obtained when **faces are full-frontal** or near to that.
- **Shutter speed** applies to video more than images however, **faster** shutter speeds tend to create a **sharper image**, which is beneficial to facial detection


**To detect faces** in Vision Studio, first **make face resource in Azure AI Vision** and the **upload** and **analyze** photos.


#### [Fundamentals of Optical Character Recognition](https://microsoftlearning.github.io/mslearn-ai-fundamentals/Instructions/Labs/05-ocr.html)


**Azure AI Vision service** - extract text from images - one of the **service is Read API** (**OCR engine** that **extracts text** (**page size**, **orientation**, **lines of text** on page, **words** in line of text incl. **bounding box** and text) from images, pdfs, TIFF files) and **organizes it by page and line**

Azure Services:
- **Azure AI Vision** - to track utilization and costs for AI Vision resource separately - **for image analysis**
- **Azure AI Language** - for **text analytics**
- **Azure AI Cognitive Services** - include Azure AI Vision and many other services - **used when** want to **simplify administration and deployment**


#### [Fundamentals of Azure AI Document Intelligence](https://learn.microsoft.com/en-in/training/modules/analyze-receipts-form-recognizer/?WT.mc_id=cloudskillschallenge_8E1F62A7-99E3-48E4-9EC9-1FFFB99EE9AF&ns-enrollment-type=Collection&ns-enrollment-id=67pkuw8qe4j4)

**Azure AI Document Intelligence/ Azure Forms Recognizer service**:

**Features grouped by model type:**

**Prebuilt model:** built to **process common document** such as invoices, receipts, forms, business cards, ID documents - **identify text and extract text**, **key-value pairs**, tables, and **structures from forms and documents**, **confidence level**

**Receipt model** - trained to **recognize data** on **several receipt types** e.g. thermal receipts, hotel, gas, credit card receipts etc.

**Fields recognized** include:
- Name, address, and telephone number of the merchant
- Date and time of the purchase
- Name, quantity, and price of each item purchased
- Total, subtotals, and tax values

**Custom models** - can be trained to identify specific fields not included in prebuilt models

**Document analysis** - returns structured data representations, incl regions of interest and inter-relationships

**To use receipt analyzer service** in Azure AI Document Intelligence, **first create** an **azure AI Document Intelligence Resource**

<!-- Forms Recognizer: 

OCR v/s Forms Recognizer 
We would still need to sort out the details and match fields to the values in OCR but automatically matches the fields to the values in Forms Recognizer  -->

### Module 7 - [Natural Language Processing](https://learn.microsoft.com/en-in/training/modules/build-faq-chatbot-qna-maker-azure-bot-service/?WT.mc_id=cloudskillschallenge_8E1F62A7-99E3-48E4-9EC9-1FFFB99EE9AF&ns-enrollment-type=Collection&ns-enrollment-id=67pkuw8qe4j4)

**Two core services:**

- **Azure AI Language:** custom **qs ans feature**
- **Azure AI Bot Service:** provides framework for **developing**, **publishing**, and **managing bots** on Azure

**Process to make bot:**
- First **make Language resource** - **use Language Studio's custom qs ans feature** - **qs ans** can be generated by **importing** an existing **FAQ doc/ web page** or **entered manually** with additional manual entries - **save it**. 
- **After created and deployed a knowledge base**, you can **deliver** it to users through a bot - create **custom bot** using **Microsoft Bot Framework SDK** ( writes code - integrates with knowledge base) 

#### [Fundamentals of Text Analysis with the Language Service](https://learn.microsoft.com/en-in/training/modules/analyze-text-with-text-analytics-service/?WT.mc_id=cloudskillschallenge_8E1F62A7-99E3-48E4-9EC9-1FFFB99EE9AF&ns-enrollment-type=Collection&ns-enrollment-id=67pkuw8qe4j4)

**Azure AI Language service** - perform **text analysis** and other **NLP tasks**

First step is a**nalyzing corpus** and **break** it **down** into **tokens** - **next** is **frequency analysis** (count no. of occurences of each token)

**Application of NLP:**

- **Analyze/ interpret** texts, docs, emails etc. (**Sentiment determination**, **extract key phrases**, **detect entities**)
- **Translate** spoken or written text between languages 
- **Interpret and implement commands** (Language understanding)

**NLP Services:**

- **Text Analytics:** includes **language detection**, **sentiment analysis** - if text +ve (1) or -ve (0), **extract key phrases**, **entity recognition** (return list of entities, categories assigned to, confidence score)
- **Speech Detection**
- **Translator**
- **Language Understanding**
- **Azure Cognitive Services**
	
**NOTE:** Any form of **text processing, analysis, or speech recognition falls under NLP** (different from **OCR** as it **only reads text from images with no processing** taking place)

#### [Fundamentals of Azure AI Speech - Speech Recognition and Speech Synthesis](https://learn.microsoft.com/en-in/training/modules/recognize-synthesize-speech/?WT.mc_id=cloudskillschallenge_8E1F62A7-99E3-48E4-9EC9-1FFFB99EE9AF&ns-enrollment-type=Collection&ns-enrollment-id=67pkuw8qe4j4)

- **Speech recognition** - ability to detect and interpret spoken input
- **Speech synthesis** - **text-to-speech API** - e.g. GPS applications, voice menus or broadcasting announcements

Services - **Azure AI Speech (own endpoint and key) and Azure Cognitive Services (1 service to rule them all)**

<!-- **Azure AI Speech** service includes following APIs:

- **Speech to text API**: Perform **real-time, batch transcription** (for presentation, demos etc) of **audio into text** format - model based on **Universal Language Model** trained by Microsoft 

-Perform **real-time, batch transcription** (for presentation, demos etc) of **audio into text** format - model based on **Universal Language Model** trained by Microsoft 
	
- **Text to speech API:** 
Converts input to audible speech - can specify voice to be used to vocalize the text - include pre-defined voices with multiple languages and regional pronounciation - can also develop custom voices and use them 

- **Speech Translation:**
used to translate speech in one language to text or speech in another
 -->
#### [Translate text and speech with Azure AI services](https://learn.microsoft.com/en-in/training/modules/translate-text-with-translation-service/?WT.mc_id=cloudskillschallenge_8E1F62A7-99E3-48E4-9EC9-1FFFB99EE9AF&ns-enrollment-type=Collection&ns-enrollment-id=67pkuw8qe4j4)

- **Azure AI Translator Service** provides **text-to-text** translation in single request API) - service uses Neural Machine Translation (NMT) model for translation - You can specify **from language with multiple to languages**, enabling simultaneous translation **from one source doc to multiple languages** - e.g. from spanish to english and french, "from" lang of "es", a "to" lang of "en", and another "to" lang of "fr" (~~and not "to" lang "en-fr"~~)

- **Azure AI Speech Service (own endpoint and key)** provides speech translation - **directly (speech-to-speech translation)** or **intermediary text format (speech-to-text format)**
  - This service includes the following APIs
    - **Speech to text API**: Perform **real-time, batch transcription** (for presentation, demos etc) of **audio into text** format - model based on **Universal Language Model** trained by Microsoft 

    - **Text to speech API:** Converts input to audible speech - can specify voice to be used to vocalize the text - include pre-defined voices with multiple languages and regional pronounciation - can also develop custom voices and use them 

    - **Speech Translation:** used to translate speech in one language to text or speech in another


- **Azure Cognitive Services**: 1 service to rule them all
	
These services translate **between** more than **60 languages**

**Extra optional configuration:**
- **Profanity filtering:** without any filtering, the service will translate the input text, without filtering out probability
- **Selective translation:** can tag content so that it is not translated

#### [Fundamentals of Conversational Language Understanding](https://learn.microsoft.com/en-in/training/modules/create-language-model-with-language-understanding/?WT.mc_id=cloudskillschallenge_8E1F62A7-99E3-48E4-9EC9-1FFFB99EE9AF&ns-enrollment-type=Collection&ns-enrollment-id=67pkuw8qe4j4)

**3 Core Concepts**:

| Utterances                           | Entities                                    | Intent                                             |
|--------------------------------------|---------------------------------------------|----------------------------------------------------|
| A **phrase** we say to the AI system | An **item** to which the phrase/utterances refers | **Purpose or goal** of phrase                        |
| Start coffee machine                 | Coffee machine                              | Start |

**Azure Services**
- **Azure AI Language** - under which **LUIS (Language Understanding Service)** works - standalone service that offers authoring, training and prediction

  - **Authoring:** Create entity and intent and select words in utterances - can be done in any order using Language Studio
  - **Training:** Teaching model to match natural language expression - then testing model - making updates and retraining model 
  - **Predicting:** publish/deploy - Client can access through prediction resource's endpoint and authentication key

- **Azure Cognitive Service** - 1 service to rule them all! (**NOTE:** This can only be used **for predictions ~~and not for authoring models~~**)

Method: Create lang resource in azure portal - create project in Language Studio - add intent_name in Schema Definition page and add min 5 utterances for an intent in Data Labelling page - then label entites - Now train the model and then deploy and test - It will provide **predicted intent, predicted entity with confidence score**

**Conversational AI**: AI systems that can chat with humans e.g. bot answering, automated responses 
**Note:** Conversational AI is only used for conversing, and is not same as NLP
































