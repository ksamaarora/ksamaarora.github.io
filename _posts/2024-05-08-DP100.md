---
layout: post
title:  "Designing and Implementing Data Science Solution on Azure (DP-100)"
date:   2024-05-08 09:29:20 +0700
tags:
  - cloud
categories: jekyll update
usemathjax: true
---

> ### <a href="/posts_blogs/blogs_dp100/datasciencelifecycle" style="color:skyblue;" rel="noopener">Data Science Life Cycle & Responsible AI Guidelines</a>

> ### Azure Machine Learning Model 

[![Screenshot-2024-05-12-at-3-53-44-PM.png](https://i.postimg.cc/mkC3Mbcq/Screenshot-2024-05-12-at-3-53-44-PM.png)](https://postimg.cc/p5VnMMJY)

> ### Resources and Assets 

[![Screenshot-2024-05-12-at-5-50-16-PM.png](https://i.postimg.cc/N0DZPCqJ/Screenshot-2024-05-12-at-5-50-16-PM.png)](https://postimg.cc/7CCB5VL0)

**Resources** provide the **infrastructure and services** to build solutions, and **assets** are the **products or content created or configured** by data scientists and data engineers.
Examples of resources include compute and datastore, and examples of assets are machine learning models and data assets.

- **Application Insights, Azure Key Vault, and Azure Storage account** are resources are **provisioned by default** when you **deploy** an Azure Machine Learning **workspace**. 

  - **Application Insights** is an extension of Azure Monitor and provides performance monitoring for several types of applications, including machine learning solutions. 
  - The **key vault** is used to store secrets required to connect to data and other resources and assets. 
  - The **storage account** is used to store machine learning notebooks and logs related to machine learning jobs and other activities.

- A **compute target** is a designated **compute resource** or **environment** where you run your training script or host your service deployment. You **can use** a **different compute target** for each phase of your project. For example, you might use a compute instance to train your model and Kubernetes for a deployed model. Compute targets can be defined for **training as well as production phases** of your Azure Machine Learning projects.

> ### Introducing Essential of Python SDK

The basic pattern used in managing Azure Machine Learning resources using the Azure Machine Learning SDK for Python starts with **importing any required libraries and classes**, then **defining the attributes and configuration** of the resource, and then executing a **create or update method**.

- **Authenticate ML Client**: From the Azure Machine Learning SDK for Python, MLClient is **used to connect to the workspace**. It is also used to execute methods that create or update resources, such as datastores and compute.
```python
from azure.ai.ml import MLClient
from azure.identity import DefaultAzureCredential
ml_client = MLClient(
    DefaultAzureCredential(), subscription_id, resource_group, workspace
)
```

- **Create New Machine Learning Workspace**
```python
from azureml.core import Workspace
my_ws = Workspace(
    name="another-workspace",
    location="westus",
    display_name="another-workspace for you to view", 
    description="This is just an example"
)
ml_client.workspaces.begin_create(my_ws)
```

- **Create a new Compute Targets**: Compute Targets are for production workloads and Compute Instances are used for powering notebooks 
```python
from azureml.core import ComputeTarget, AmlCompute
my_little_cluster = AmlCompute(
    name="basic-cluster",
    type="amlcompute",
    size="STANDARD_DS3_v2",
    location="westus",
    min_instances=0,
    max_instances=2,
    idle_time_before_scale_down=60,
)
ml_client.begin_create_or_update (my_little_cluster)
```

- **Create a new Datastore**
```python
from azureml.core import Datastore, AzureBlobDatastore 
a_blob_store= AzureBlobDatastore(
    name="my_blob_example",
    description="Datastore pointing to a blob container.",
    account_name="myexistingblobstore", 
    container_name="stuffandsuch-container",
    credentials={
        "account_key": "XXXXYYYXXXzzzYYYZZZxxx"
    },
)
ml_client.create_or_update(blob_datastore1)
```

- **Create List Environments**
```python
envs = ml_client.environments.list()
for env in envs:
    print(env.name)
```

- **Create a Custom Environment** 
```python
from azureml.core import Environment
my_env = Environment(
    image="pytorch/pytorch: latest", # base image to use
    name="docker-image-example", # name of the model
    description="Environment created from a Docker image.",
)
ml_client.environments.create_or_update(my_env) # use the MLClient to connect to workspace and create/register the environment
```

> ### Compute

| **Compute Type** | **Description** |
|---|---|
| **Compute Instances** | The engine that powers your machine learning experiments. Used for everyday starting builds. Just like a Virtual Machine. |
| **Compute Clusters** | Think of compute clusters as a bunch of workers. We can scale our work using compute clusters as we can increase the number of nodes (workers) used for a particular task/ workload. Used for large runs. |
| | - **Dedicated Cluster:** These are just ready when you are - more expensive |
| | - **Low-Priority Cluster:** These systems are going to be ready when you are, probably. Low priority clusters may be accessed by multiple users thus you may get access to it but just in a few minutes or so - less expensive |
| **Inference Cluster/Kubernetes Cluster** | We will be using Azure Kubernetes or AksCompute Cluster. This will be useful for Production environments, Multi-cloud environments, On-premises |
| **Attached Compute** | "Catch-All". Used for Specialized needs. This is useful for HDInsight cluster, Virtual Machine, Databricks cluster, Data Lake Analytics, Azure Synapse Spark Pool |

<!-- Compute Instances 
[![Screenshot-2024-05-13-at-3-16-08-AM.png](https://i.postimg.cc/KjXNVNBj/Screenshot-2024-05-13-at-3-16-08-AM.png)](https://postimg.cc/mzwC17dW)

Compute Cluster
[![Screenshot-2024-05-13-at-3-17-46-AM.png](https://i.postimg.cc/LXW7sLfF/Screenshot-2024-05-13-at-3-17-46-AM.png)](https://postimg.cc/62dzj7YM)

[![Screenshot-2024-05-13-at-3-18-26-AM.png](https://i.postimg.cc/pd44WKKb/Screenshot-2024-05-13-at-3-18-26-AM.png)](https://postimg.cc/Y4Nb8GXb)

Interference Cluster 
[![Screenshot-2024-05-13-at-3-20-09-AM.png](https://i.postimg.cc/dtf8SnFY/Screenshot-2024-05-13-at-3-20-09-AM.png)](https://postimg.cc/crQgvR69)

Attached Compute
[![Screenshot-2024-05-13-at-3-21-09-AM.png](https://i.postimg.cc/yWC7kw9K/Screenshot-2024-05-13-at-3-21-09-AM.png)](https://postimg.cc/p5CwScqc) -->


> ### Apache Spark Tools as Compute Targets

**Azure Synapse:** It is an enterprise analytics service platform that enables data warehousing, analytics, processing and integration and pipeline framed with a massively parallel processing architecture. Synapse supports bot SQL and Spark technologies. 

**Azure Synapse Spark Pools:**

- When setting up a Synapse Spark pool as an attached compute target in Azure Machine Learning studio:
Select an existing Azure Synapse workspace and an existing Spark pool in that workspace -> tick the option to set up a **managed identity** -> Choose system-assigned or user-assigned -> To **reliably connect to your new compute resource** to run workloads, Go to synapse studio and **assign managed identity in Azure ML to role of Synapse Administrator**. 

- **Serverless Spark Pools** can be used as a form of compute to set up notebooks in Azure ML Studio

> ### Selecting development approaches to build or train models

Three ways to interact with Azure Machine Learning
  - **Azure CLI:** Following command is used to define an compute resource and then create a Azure ML Workspace
    - ```python
      az ml compute create -f create-cluster.yml
      ```
  - **Python SDK:** Previously mentioned codes are used for developing and training models 
  - **Azure ML Studio:** used for low code training and development, data management and monitoring
  - **Git:** Azure ML Workspaces work indirectly with Git for **source control**, and you can use a local Git repository by cloning it
    - ```python
     git clone url_of_repository
     ```
  - **Environments:** Can be another form of **source control** and multiple custom environments can be created or curated environments can be used.

**Note:** Azure CLI, AML studio, and Azure Machine Learning SDK for Python are all commonly used in at least one phase of building, training, and deploying models in Azure Machine Learning. 

[![Screenshot-2024-05-13-at-3-31-18-AM.png](https://i.postimg.cc/2SHqc7ZD/Screenshot-2024-05-13-at-3-31-18-AM.png)](https://postimg.cc/hXdPhxsy)

> #### Azure Machine Learning Environments

**Environment:** Contains python packages, environment variables, software settings, runtimes. Environment ensures version control, reproducible and auditable. 

- **Types of Environment:**
  - **Curated Environment:** Microsoft is responsible for everything
  - **User-Managed Environment:** You are responsible for everything
  - **System Managed:** Conda is responsible for everything

> ### Attached Compute - HD Insights and Apache Spark

```python
from azureml.core import RemoteCompute, ComputeTarget
# Ubuntu VMs only
# VM must have public IP addy
my_resource_id = "/subscriptions/<subscription_id>/resourceGroups/<resource_group>/providers/Microsoft.Compute/virtualMachines/<vm_name>"
my_compute_target_name = "attached_existingVM"
attached_target_config = RemoteCompute.attach
#
attach_config = RemoteCompute.attach_configuration(resource_id='<resource_id>',
                                                    ssh_port=22,
                                                    username= '<username>'
                                                    password="<password>")
# Attach the compute
compute = ComputeTarget.attach(my_ws, my_compute_target_name, attached_target_config)
compute.wait_for_completion (show_output=True)
```

**Note:** When considering attaching an existing virtual machine to your Azure ML workspace as a compute target, it's crucial that the **external Vms** must be **Ubuntu only** and must have an **public IP address only**.  
However, the primary reason for **choosing an existing VM** over a new compute instance is to **utilize unused capacity effectively**.

```python
from azureml.core import ScriptRunConfig
from azureml.core.environment import Environment
from azureml.core.conda_dependencies import CondaDependencies

# Create environment
my_env = Environment(name="mycoenv")

# Dependencies
my_env.python.conda_dependencies = CondaDependencies.create(conda_packages=['scikit-learn'])

# Base Image. Leave out to use the default image: "azureml.core.runconfig.DEFAULT_CPU_IMAGE"

# Configure with the existing VM as the compute target, using the environment we just defined 
src = ScriptRunConfig(source_directory=".", script="train.py", compute_target=compute, environment=my_env)
```

> ### <a href="/posts_blogs/blogs_dp100/Lab1CreateMLWorkspace" style="color:skyblue;" rel="noopener">Create Azure Machine Learning Workspace - Lab 1</a>











